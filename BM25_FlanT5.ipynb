{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkglLrhK9pvs"
      },
      "source": [
        "## **Drive Mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 21554,
          "status": "ok",
          "timestamp": 1760244604854,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "wjyB9kTXtIz6",
        "outputId": "d1952b92-41ac-427b-dbb7-ae19eb319b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1RnnhT7taVO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBsAZOYXbiZv"
      },
      "source": [
        "## **Is the Dataset Cleaned?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1752862604657,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "x4C4b7OVwK3M",
        "outputId": "4b8c2926-c6e7-42d6-c658-0466332b2e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         query_clean  \\\n",
            "0  a woke up this morning feeling the whole room ...   \n",
            "1  by baby has been pooing 5-6 times a day for a ...   \n",
            "2  hello , by husband is taking oxycodone due to ...   \n",
            "3  lump under left nipple and stomach pain ( male...   \n",
            "4  a have a 5 month old baby who is very congeste...   \n",
            "\n",
            "                                      response_clean  \\\n",
            "0  hi, thank you for posting your query. the most...   \n",
            "1  hi... thank you for consulting in chat doctor....   \n",
            "2  hello, and i hope i can help you today.first, ...   \n",
            "3  hi. you have two different problems. the lump ...   \n",
            "4  thank you for using chat doctor. i would sugge...   \n",
            "\n",
            "                                     query_sentences  \\\n",
            "0  ['a woke up this morning feeling the whole roo...   \n",
            "1  ['by baby has been pooing 5-6 times a day for ...   \n",
            "2  ['hello , by husband is taking oxycodone due t...   \n",
            "3  ['lump under left nipple and stomach pain ( ma...   \n",
            "4  ['a have a 5 month old baby who is very conges...   \n",
            "\n",
            "                                  response_sentences  \\\n",
            "0  ['hi, thank you for posting your query.', 'the...   \n",
            "1  ['hi...', 'thank you for consulting in chat do...   \n",
            "2  ['hello, and i hope i can help you today.first...   \n",
            "3  ['hi.', 'you have two different problems.', 't...   \n",
            "4  ['thank you for using chat doctor.', 'i would ...   \n",
            "\n",
            "                                        query_tokens  \\\n",
            "0  ['a', 'woke', 'up', 'this', 'morning', 'feelin...   \n",
            "1  ['by', 'baby', 'has', 'been', 'pooing', '5-6',...   \n",
            "2  ['hello', ',', 'by', 'husband', 'is', 'taking'...   \n",
            "3  ['lump', 'under', 'left', 'nipple', 'and', 'st...   \n",
            "4  ['a', 'have', 'a', '5', 'month', 'old', 'baby'...   \n",
            "\n",
            "                                     response_tokens  \\\n",
            "0  ['hi', ',', 'thank', 'you', 'for', 'posting', ...   \n",
            "1  ['hi', '...', 'thank', 'you', 'for', 'consulti...   \n",
            "2  ['hello', ',', 'and', 'i', 'hope', 'i', 'can',...   \n",
            "3  ['hi', '.', 'you', 'have', 'two', 'different',...   \n",
            "4  ['thank', 'you', 'for', 'using', 'chat', 'doct...   \n",
            "\n",
            "                                      query_entities  \\\n",
            "0  [[('this morning', 'TIME')], [], [('few hours'...   \n",
            "1  [[('5', 'CARDINAL'), ('a week', 'DATE')], [('t...   \n",
            "2  [[], [('one month', 'DATE')], [('second', 'ORD...   \n",
            "3  [[('a few weeks ago', 'DATE'), ('a quarter', '...   \n",
            "4        [[('5 month old', 'DATE')], [], [], [], []]   \n",
            "\n",
            "                                   response_entities  \n",
            "0  [[], [], [], [], [('a few days', 'DATE')], [],...  \n",
            "1  [[], [], [], [('5-7 days', 'DATE')], [], [], [...  \n",
            "2          [[], [], [], [], [('daily', 'DATE')], []]  \n",
            "3  [[], [('two', 'CARDINAL')], [], [], [('second'...  \n",
            "4                   [[], [], [], [], [], [], [], []]  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 46,
          "status": "ok",
          "timestamp": 1752862619880,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "OpH6aTVewNHF",
        "outputId": "6ca19af5-ab22-43eb-d78d-7cb32835114d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         query_clean  \\\n",
            "0  a woke up this morning feeling the whole room ...   \n",
            "1  by baby has been pooing 5-6 times a day for a ...   \n",
            "2  hello , by husband is taking oxycodone due to ...   \n",
            "3  lump under left nipple and stomach pain ( male...   \n",
            "4  a have a 5 month old baby who is very congeste...   \n",
            "5  a am a 38 in good shape work out ( do triathlo...   \n",
            "6  sir , of uncle has ild-interstitial lung disea...   \n",
            "7  my husband was working on a project in the hou...   \n",
            "8  hi my nine year old son had a cough and flu sy...   \n",
            "9  gino problemsfor the past few months , a have ...   \n",
            "\n",
            "                                      response_clean  \n",
            "0  hi, thank you for posting your query. the most...  \n",
            "1  hi... thank you for consulting in chat doctor....  \n",
            "2  hello, and i hope i can help you today.first, ...  \n",
            "3  hi. you have two different problems. the lump ...  \n",
            "4  thank you for using chat doctor. i would sugge...  \n",
            "5  hi, from history it seems that you might be ha...  \n",
            "6  thanks for your question on chat doctor. i can...  \n",
            "7  hello. it could be a blood collection due to m...  \n",
            "8  hi, if the symptoms persist that long this sug...  \n",
            "9  dear friend. welcome to chat doctor. i am chat...  \n"
          ]
        }
      ],
      "source": [
        "print(df[[\"query_clean\", \"response_clean\"]].head(10))  # First 10 Q&A pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1752862654590,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "5eP2er9xwQXm",
        "outputId": "4a56a98a-f1f2-4bdc-9c24-232cd99d03b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['query_clean', 'response_clean', 'query_sentences', 'response_sentences', 'query_tokens', 'response_tokens', 'query_entities', 'response_entities']\n"
          ]
        }
      ],
      "source": [
        "print(df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "executionInfo": {
          "elapsed": 2238,
          "status": "ok",
          "timestamp": 1752862669863,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "JiDJG7Rvwab9",
        "outputId": "ae77e23d-d677-4e2a-c596-d0abb10ead2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 112165 entries, 0 to 112164\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count   Dtype \n",
            "---  ------              --------------   ----- \n",
            " 0   query_clean         112164 non-null  object\n",
            " 1   response_clean      112165 non-null  object\n",
            " 2   query_sentences     112165 non-null  object\n",
            " 3   response_sentences  112165 non-null  object\n",
            " 4   query_tokens        112165 non-null  object\n",
            " 5   response_tokens     112165 non-null  object\n",
            " 6   query_entities      112165 non-null  object\n",
            " 7   response_entities   112165 non-null  object\n",
            "dtypes: object(8)\n",
            "memory usage: 6.8+ MB\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"query_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          112140,\n          \"3\",\n          \"112164\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          110430,\n          \"153\",\n          \"112165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          112141,\n          \"3\",\n          \"112165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          110430,\n          \"153\",\n          \"112165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          112141,\n          \"3\",\n          \"112165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          110428,\n          \"153\",\n          \"112165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          96551,\n          \"1798\",\n          \"112165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          60445,\n          \"5436\",\n          \"112165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3490e8e9-f3a8-437f-972d-d82b7afe1c11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_clean</th>\n",
              "      <th>response_clean</th>\n",
              "      <th>query_sentences</th>\n",
              "      <th>response_sentences</th>\n",
              "      <th>query_tokens</th>\n",
              "      <th>response_tokens</th>\n",
              "      <th>query_entities</th>\n",
              "      <th>response_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>112164</td>\n",
              "      <td>112165</td>\n",
              "      <td>112165</td>\n",
              "      <td>112165</td>\n",
              "      <td>112165</td>\n",
              "      <td>112165</td>\n",
              "      <td>112165</td>\n",
              "      <td>112165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>112140</td>\n",
              "      <td>110430</td>\n",
              "      <td>112141</td>\n",
              "      <td>110430</td>\n",
              "      <td>112141</td>\n",
              "      <td>110428</td>\n",
              "      <td>96551</td>\n",
              "      <td>60445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>a 54-year-old type-a male business executive h...</td>\n",
              "      <td>hi... thank you for consulting in chat doctor....</td>\n",
              "      <td>['a 54-year-old type-a male business executive...</td>\n",
              "      <td>['hi...', 'thank you for consulting in chat do...</td>\n",
              "      <td>['a', '54-year-old', 'type-a', 'male', 'busine...</td>\n",
              "      <td>['hi', '...', 'thank', 'you', 'for', 'consulti...</td>\n",
              "      <td>[[], [], [], []]</td>\n",
              "      <td>[[], [], [], [], [], [], []]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>153</td>\n",
              "      <td>3</td>\n",
              "      <td>153</td>\n",
              "      <td>3</td>\n",
              "      <td>153</td>\n",
              "      <td>1798</td>\n",
              "      <td>5436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3490e8e9-f3a8-437f-972d-d82b7afe1c11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3490e8e9-f3a8-437f-972d-d82b7afe1c11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3490e8e9-f3a8-437f-972d-d82b7afe1c11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-54e13152-45b1-41b4-81f3-63df7d68ad7f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54e13152-45b1-41b4-81f3-63df7d68ad7f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-54e13152-45b1-41b4-81f3-63df7d68ad7f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              query_clean  \\\n",
              "count                                              112164   \n",
              "unique                                             112140   \n",
              "top     a 54-year-old type-a male business executive h...   \n",
              "freq                                                    3   \n",
              "\n",
              "                                           response_clean  \\\n",
              "count                                              112165   \n",
              "unique                                             110430   \n",
              "top     hi... thank you for consulting in chat doctor....   \n",
              "freq                                                  153   \n",
              "\n",
              "                                          query_sentences  \\\n",
              "count                                              112165   \n",
              "unique                                             112141   \n",
              "top     ['a 54-year-old type-a male business executive...   \n",
              "freq                                                    3   \n",
              "\n",
              "                                       response_sentences  \\\n",
              "count                                              112165   \n",
              "unique                                             110430   \n",
              "top     ['hi...', 'thank you for consulting in chat do...   \n",
              "freq                                                  153   \n",
              "\n",
              "                                             query_tokens  \\\n",
              "count                                              112165   \n",
              "unique                                             112141   \n",
              "top     ['a', '54-year-old', 'type-a', 'male', 'busine...   \n",
              "freq                                                    3   \n",
              "\n",
              "                                          response_tokens    query_entities  \\\n",
              "count                                              112165            112165   \n",
              "unique                                             110428             96551   \n",
              "top     ['hi', '...', 'thank', 'you', 'for', 'consulti...  [[], [], [], []]   \n",
              "freq                                                  153              1798   \n",
              "\n",
              "                   response_entities  \n",
              "count                         112165  \n",
              "unique                         60445  \n",
              "top     [[], [], [], [], [], [], []]  \n",
              "freq                            5436  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.info()\n",
        "df.describe(include='all')  # For summary stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "executionInfo": {
          "elapsed": 57,
          "status": "ok",
          "timestamp": 1752862714068,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "85vm6Hkgwlqm",
        "outputId": "b3d1ddb1-1cc7-4fae-e557-d4ac16023c11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>query_clean</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_clean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_tokens</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_tokens</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_entities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_entities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "query_clean           1\n",
              "response_clean        0\n",
              "query_sentences       0\n",
              "response_sentences    0\n",
              "query_tokens          0\n",
              "response_tokens       0\n",
              "query_entities        0\n",
              "response_entities     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "executionInfo": {
          "elapsed": 152,
          "status": "ok",
          "timestamp": 1752907652106,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "DDF3YlwNcAqR",
        "outputId": "e3adc95d-5b59-48e7-e4d7-0472a79f0a51"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[[\\\"query_clean\\\", \\\"response_clean\\\", \\\"query_entities\\\", \\\"response_entities\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"query_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"a have a small lump under my armpit . there is actually 2 but they feel like they may be connected to each other but i can feel them separately . its only sore if i press it but its not very sore . you cant see the lump by just looking at it but you can see that it looks like there is a small bruise on top of it . would this be serious ? that could it be ?\",\n          \"i , may a answer your health queries right now ? please type your query here ... a am 42 year old female with known case of pneumonia and constant coughing and low body temp of 35.3c feeling anaemic advise please ? currently using dioxin and guafinicine/codein\",\n          \"by father in law was diagnosed with small cell lung cancer september 2009 , has had chemotherapy and radiotherapy , and was told he was in remission september 2010 . however , he still has poor appetite , very tired , and his left arm is very swollen from the elbow down , no pain , and despite blood tests etc , has been told there is no identifiable cause for this swelling . often in the morning his parlour is very grey , he is very fatigued . be are obviously very concerned .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"welcome to chat doctor .1. yes, it can be serious if you ignore.2. suggest to get an appointment with your doctor - let him examine the area.3. it can be carbuncle/fur uncle may need incision and chat doctor. 4. if they are in early stage a course of antibiotic would be enough.5. so see your doctor as soon you can get an appointment and act accordingly.6. your age and underlying causes may change the diagnosis accordingly. anything to ask ? do not hesitate. thank you.\",\n          \"thanks for your question on chat doctor. i can understand your concern. constant coughing and hypothermia (low body temperature) in pneumonia patient can be due to1. worsening of underlying pneumonia2. bronchitis better to consult pulmonologist and get done clinical examination of respiratory system, chest x-ray and pft (pulmonary function test). yoi may need higher antibiotic and inhaled bronchodilators (formoterol or albuterol).don't worry, you will be alright with all these. hope i have solved your query. i will be happy to help you further. wish you good health. thanks.\",\n          \"hi welcome to chat doctor i have gone through your very. your father in laws sufferings, inspire of being in remission is a matter of great concern. i as a homeopath, naturopath and magneto therapist would like to help you in this. these are no nonsense having no side effects and potent tools for recovery & prevention>you can administer him homeopathic carcinogen 200. one dose every fortnight, i ar's nic 30 is wonderful remedy to relieve, tiredness, swelling. take 4 chat doctor. make 3 doses , each dose half-hourly.administer him some supplements rich in antioxidants which add to enhance power of metabolism and strengthen immune system to help him early recovery and assure stopping endurance....1. give high fiber diets including all essential nutrients, directly, as it reduce the risk of colon or any cancer, a fiber-rich diet can decrease and eliminate constipation and hemorrhoids, it helps the stool pass through easily and decreases the burden of toxins reabsorbed into the body. avoid fried fast food, tea coffee, alcohol and smoking .2. give mixture of extract of lemon, garlic, ginger, mooring tree bark(sean tree), vinegar of coconut water and honey. 25 -35 ml is the dose with equal water for 3 -4 days twice 1/2 hour before meals, and after that, pure mixture for 25 - 35 days as required, is great antioxidant and rejuvenating, preventive and curative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[[], [('2', 'CARDINAL')], [], [], [], []]\",\n          \"[[], [('42 year old', 'DATE'), ('35.3c', 'CARDINAL')], []]\",\n          \"[[('september 2009', 'DATE'), ('september 2010', 'DATE')], [], [('the morning', 'TIME')], []]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[[], [], [], [], [('4', 'CARDINAL')], [], [], [], [], [], []]\",\n          \"[[], [], [], [], [], [(\\\"albuterol).don't\\\", 'CARDINAL')], [], [], [], []]\",\n          \"[[], [], [], [('200', 'CARDINAL')], [('one', 'CARDINAL'), ('30', 'CARDINAL')], [('4', 'CARDINAL')], [('3', 'CARDINAL'), ('1', 'CARDINAL')], [], [], [], [('25 -35 ml', 'QUANTITY'), ('3 -4 days', 'DATE'), ('twice 1/2 hour', 'TIME'), ('25 - 35 days', 'DATE')]]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0edbfb4d-74eb-403a-8c62-f176ae554bfc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_clean</th>\n",
              "      <th>response_clean</th>\n",
              "      <th>query_entities</th>\n",
              "      <th>response_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>87510</th>\n",
              "      <td>a am concerned a am losing my hair or having i...</td>\n",
              "      <td>hi dear, understanding your concern. as per yo...</td>\n",
              "      <td>[[], [('21', 'DATE')], [], [], [], [], [], [('...</td>\n",
              "      <td>[[], [], [], [], [], [], [('indian', 'NORP'), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52843</th>\n",
              "      <td>a have a small lump under my armpit . there is...</td>\n",
              "      <td>welcome to chat doctor .1. yes, it can be seri...</td>\n",
              "      <td>[[], [('2', 'CARDINAL')], [], [], [], []]</td>\n",
              "      <td>[[], [], [], [], [('4', 'CARDINAL')], [], [], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4827</th>\n",
              "      <td>by father in law was diagnosed with small cell...</td>\n",
              "      <td>hi welcome to chat doctor i have gone through ...</td>\n",
              "      <td>[[('september 2009', 'DATE'), ('september 2010...</td>\n",
              "      <td>[[], [], [], [('200', 'CARDINAL')], [('one', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87370</th>\n",
              "      <td>my daughter is eleven years old , december she...</td>\n",
              "      <td>hello, i can understand your problem. repeated...</td>\n",
              "      <td>[[('eleven years old', 'DATE'), ('december', '...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], []]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29955</th>\n",
              "      <td>i , may a answer your health queries right now...</td>\n",
              "      <td>thanks for your question on chat doctor. i can...</td>\n",
              "      <td>[[], [('42 year old', 'DATE'), ('35.3c', 'CARD...</td>\n",
              "      <td>[[], [], [], [], [], [(\"albuterol).don't\", 'CA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0edbfb4d-74eb-403a-8c62-f176ae554bfc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0edbfb4d-74eb-403a-8c62-f176ae554bfc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0edbfb4d-74eb-403a-8c62-f176ae554bfc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3d092c90-2385-49f7-a79b-2e8b1bf0638f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d092c90-2385-49f7-a79b-2e8b1bf0638f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3d092c90-2385-49f7-a79b-2e8b1bf0638f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             query_clean  \\\n",
              "87510  a am concerned a am losing my hair or having i...   \n",
              "52843  a have a small lump under my armpit . there is...   \n",
              "4827   by father in law was diagnosed with small cell...   \n",
              "87370  my daughter is eleven years old , december she...   \n",
              "29955  i , may a answer your health queries right now...   \n",
              "\n",
              "                                          response_clean  \\\n",
              "87510  hi dear, understanding your concern. as per yo...   \n",
              "52843  welcome to chat doctor .1. yes, it can be seri...   \n",
              "4827   hi welcome to chat doctor i have gone through ...   \n",
              "87370  hello, i can understand your problem. repeated...   \n",
              "29955  thanks for your question on chat doctor. i can...   \n",
              "\n",
              "                                          query_entities  \\\n",
              "87510  [[], [('21', 'DATE')], [], [], [], [], [], [('...   \n",
              "52843          [[], [('2', 'CARDINAL')], [], [], [], []]   \n",
              "4827   [[('september 2009', 'DATE'), ('september 2010...   \n",
              "87370  [[('eleven years old', 'DATE'), ('december', '...   \n",
              "29955  [[], [('42 year old', 'DATE'), ('35.3c', 'CARD...   \n",
              "\n",
              "                                       response_entities  \n",
              "87510  [[], [], [], [], [], [], [('indian', 'NORP'), ...  \n",
              "52843  [[], [], [], [], [('4', 'CARDINAL')], [], [], ...  \n",
              "4827   [[], [], [], [('200', 'CARDINAL')], [('one', '...  \n",
              "87370               [[], [], [], [], [], [], [], [], []]  \n",
              "29955  [[], [], [], [], [], [(\"albuterol).don't\", 'CA...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[[\"query_clean\", \"response_clean\", \"query_entities\", \"response_entities\"]].sample(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "executionInfo": {
          "elapsed": 11518,
          "status": "ok",
          "timestamp": 1752907679549,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "I6yIqVlacE3Z",
        "outputId": "c049cc5c-022b-45a1-d7f7-f025fb2c2168"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[[\\\"num_query_entities\\\", \\\"num_response_entities\\\"]]\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"num_query_entities\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39651.082758880475,\n        \"min\": 0.0,\n        \"max\": 112165.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.152935407658361,\n          5.0,\n          112165.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_response_entities\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39651.64182255468,\n        \"min\": 1.0,\n        \"max\": 112165.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8.804386395043016,\n          8.0,\n          112165.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4e2ba018-a9b6-4da1-a328-9f6ddd64cbf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_query_entities</th>\n",
              "      <th>num_response_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>112165.000000</td>\n",
              "      <td>112165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.152935</td>\n",
              "      <td>8.804386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.638815</td>\n",
              "      <td>3.812210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>54.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e2ba018-a9b6-4da1-a328-9f6ddd64cbf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e2ba018-a9b6-4da1-a328-9f6ddd64cbf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e2ba018-a9b6-4da1-a328-9f6ddd64cbf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5d2b071d-8a7d-4186-bce9-4e3b1555051c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d2b071d-8a7d-4186-bce9-4e3b1555051c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5d2b071d-8a7d-4186-bce9-4e3b1555051c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       num_query_entities  num_response_entities\n",
              "count       112165.000000          112165.000000\n",
              "mean             5.152935               8.804386\n",
              "std              3.638815               3.812210\n",
              "min              0.000000               1.000000\n",
              "25%              3.000000               6.000000\n",
              "50%              5.000000               8.000000\n",
              "75%              7.000000              11.000000\n",
              "max             80.000000              54.000000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ast\n",
        "\n",
        "df[\"num_query_entities\"] = df[\"query_entities\"].apply(lambda x: len(ast.literal_eval(str(x))))\n",
        "df[\"num_response_entities\"] = df[\"response_entities\"].apply(lambda x: len(ast.literal_eval(str(x))))\n",
        "\n",
        "df[[\"num_query_entities\", \"num_response_entities\"]].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "executionInfo": {
          "elapsed": 641,
          "status": "ok",
          "timestamp": 1752907697079,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "IpSHDzVhcLeh",
        "outputId": "f9225189-1d38-4347-d51a-57d68851a85d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"num_query_entities\"].hist(bins=20, alpha=0.6, label='Query Entities')\n",
        "df[\"num_response_entities\"].hist(bins=20, alpha=0.6, label='Response Entities')\n",
        "plt.title(\"Entity Counts in Query vs Response\")\n",
        "plt.xlabel(\"Number of Entities\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 56,
          "status": "ok",
          "timestamp": 1752907722585,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "gHJ2UAXEcSFS",
        "outputId": "f4d46df2-5c8a-4f87-f3b1-9aabb2f03570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "has_entities\n",
            "True    112165\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df[\"has_entities\"] = (df[\"num_query_entities\"] > 0) | (df[\"num_response_entities\"] > 0)\n",
        "print(df[\"has_entities\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "executionInfo": {
          "elapsed": 95,
          "status": "ok",
          "timestamp": 1752907743321,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "vC-dUFHxcXHz",
        "outputId": "073b0b8a-2ba9-48d9-b014-1b0a5cddb6c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_clean</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hi... thank you for consulting in chat doctor. skin conditions are best diagnosed only after seeing directly. i suggest you to upload photographs of the same on this website, so that i can guide you scientifically. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.</th>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi... thank you for consulting in chat doctor. it seems your kid is having viral diarrhea. once it starts it will take 5-7 days to completely get better. unless the kids having low urine output or very dull or excessively sleepy or blood in motion or green bilious vomiting...you need not worry. there is no need to use antibiotics unless there is blood in the motion. antibiotics might worsen if unnecessarily used causing antibiotic associated diarrhea. i suggest you use zinc supplements (z&amp;d chat doctor.</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi... thank you for consulting in chat doctor. cough and cold are viral 95% of the times in child chat doctor. for cold, you can use anti-allergics like cetirizine and for nose block, saline nasal decongestants will do. paracetamol can be given in the dose of 15 mg/kg/dose (max ceiling dose 500 mg) every 4-6th hourly, that too only if fever is more than 100f. i suggest not using combination medicines for fever, especially with paracetamol. for cold, you can use cetirizine at 0.25 mg/kg/dose every 12 hourly for 3 days. for nasal block, plain saline nasal</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi hope this message finds u in good health. i have gone through your msg and understand your concern.it may be due to some sort of hormonal imbalances or variations in the body, though there may be other reasons as reclothing to worry about, you should eventually get back to normal. take multi vitamin and calcium supplements do consult a gynecologist if symptoms worsened back to me for any follow-up queries anytime. chat doctor. .(mbbs, ms,mch)</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi... thank you for consulting in chat doctor. fever of few days without any localizing signs could as well a viral illness. usually rather than fever, what is more important is the activity of the child, in between 2 fever episodes on the same day. if the kid is active and playing around when there is no fever, it is probably viral illness and it doesn't require antibiotics at all. once viral fever comes it will there for 4-7 days. so do not worry about duration if the kid is active. paracetamol can be given in the dose of 15 mg/kg/dose (maximum ceiling dose of 500 mg) every 4-6th hourly that too only if fever is more than 100f. i suggest not using combination medicines for fever, especially with paracetamol. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi... i feel by what you quote he should be having a - hand foot mouth disease. this is one viral illness among all other anthems which can cause fever followed by rash over palms and soles. it is a self-limiting disorder and itching can be really worrisome. i suggest you use any over the counter antihistamine if you have one with you now. you can use hy chat doctor. this can even cause some peeling of skin in the next 4-6 weeks and do not worry about it. regards -</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hello, thank you for posting on chat doctor. the condition you have referred to is called urticaria or hives. it's an allergic manifestation of skin, where an allergen leads to release of certain substances from your blood, leading to itchy skin rash and swelling over soft tissues. its proper management requires thorough history, clinical and laboratory work-up. you may have to go for specific tests like patch test, food prick test, ige antibody levels etc. as for treatment part, best would be the avoidance of allergen as far as possible. try to eliminate possible triggering foods from diet. i would also advise you various antihistamines for long duration(at least 3 months) with or without oral corticosteroids. for non-responding cases there are many other chat doctor. hope this will help you in resolving your query. thank you</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi... thank you for consulting in chat doctor. by what you quote it should be an urticaria or a simple skin allergy. you can use hy chat doctor. most important thing to be remembered is that it has a propensity to recur (called as second crop) within 10-14 days. if this happens, you can start using the same medicine, but i suggest you get the kid evaluated with your pediatrician. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hello, thank you for posting on chat doctor. it seems you are suffering from tina courts and corporal, a kind of fungal infection. i would suggest you to consult your dermatologist for proper management of the condition. i usually recommend proper course of oral antifungal chat doctor. you can additionally use antifungal dusting powder containing ketoconazole during daytime and a soap containing ketoconazole for rinsing of affected areas. take oral antihistamines for itching as required. maintain hygiene over those areas and avoid wearing tight undergarments. hope your queries are resolved and wish you best of health. kindly spare some time to rate my answer and</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi... thank you for consulting in chat doctor. i think your kid is having habitual constipation. i have certain questions and suggestions for you. questions:1. did your kid pass motion or meconium on day one of life?2. since how long is the kid constipated?3. does the kid have any bleeding along with hard stools?4. how much milk does the kid consume per day?5. does the kid eat fruits and vegetables (fiber diet) appropriately? you can get back with answers at the following link - .com/doctors/ chat doctor. natural methods are the best to relieve constipation.2. constipation is a risk factor for uti3. maximum milk consumption per day should not exceed 300-400ml4. minimum 3-4 cups of fruits and vegetables to be consumed per day5. toilet training - that is - sitting in indian type of lavatory daily at the same time will help a lot. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "response_clean\n",
              "hi... thank you for consulting in chat doctor. skin conditions are best diagnosed only after seeing directly. i suggest you to upload photographs of the same on this website, so that i can guide you scientifically. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     153\n",
              "hi... thank you for consulting in chat doctor. it seems your kid is having viral diarrhea. once it starts it will take 5-7 days to completely get better. unless the kids having low urine output or very dull or excessively sleepy or blood in motion or green bilious vomiting...you need not worry. there is no need to use antibiotics unless there is blood in the motion. antibiotics might worsen if unnecessarily used causing antibiotic associated diarrhea. i suggest you use zinc supplements (z&d chat doctor.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          95\n",
              "hi... thank you for consulting in chat doctor. cough and cold are viral 95% of the times in child chat doctor. for cold, you can use anti-allergics like cetirizine and for nose block, saline nasal decongestants will do. paracetamol can be given in the dose of 15 mg/kg/dose (max ceiling dose 500 mg) every 4-6th hourly, that too only if fever is more than 100f. i suggest not using combination medicines for fever, especially with paracetamol. for cold, you can use cetirizine at 0.25 mg/kg/dose every 12 hourly for 3 days. for nasal block, plain saline nasal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       55\n",
              "hi hope this message finds u in good health. i have gone through your msg and understand your concern.it may be due to some sort of hormonal imbalances or variations in the body, though there may be other reasons as reclothing to worry about, you should eventually get back to normal. take multi vitamin and calcium supplements do consult a gynecologist if symptoms worsened back to me for any follow-up queries anytime. chat doctor. .(mbbs, ms,mch)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     51\n",
              "hi... thank you for consulting in chat doctor. fever of few days without any localizing signs could as well a viral illness. usually rather than fever, what is more important is the activity of the child, in between 2 fever episodes on the same day. if the kid is active and playing around when there is no fever, it is probably viral illness and it doesn't require antibiotics at all. once viral fever comes it will there for 4-7 days. so do not worry about duration if the kid is active. paracetamol can be given in the dose of 15 mg/kg/dose (maximum ceiling dose of 500 mg) every 4-6th hourly that too only if fever is more than 100f. i suggest not using combination medicines for fever, especially with paracetamol. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.                                                                                                                             38\n",
              "hi... i feel by what you quote he should be having a - hand foot mouth disease. this is one viral illness among all other anthems which can cause fever followed by rash over palms and soles. it is a self-limiting disorder and itching can be really worrisome. i suggest you use any over the counter antihistamine if you have one with you now. you can use hy chat doctor. this can even cause some peeling of skin in the next 4-6 weeks and do not worry about it. regards -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 35\n",
              "hello, thank you for posting on chat doctor. the condition you have referred to is called urticaria or hives. it's an allergic manifestation of skin, where an allergen leads to release of certain substances from your blood, leading to itchy skin rash and swelling over soft tissues. its proper management requires thorough history, clinical and laboratory work-up. you may have to go for specific tests like patch test, food prick test, ige antibody levels etc. as for treatment part, best would be the avoidance of allergen as far as possible. try to eliminate possible triggering foods from diet. i would also advise you various antihistamines for long duration(at least 3 months) with or without oral corticosteroids. for non-responding cases there are many other chat doctor. hope this will help you in resolving your query. thank you                                                                                                                                                                                                                                                                29\n",
              "hi... thank you for consulting in chat doctor. by what you quote it should be an urticaria or a simple skin allergy. you can use hy chat doctor. most important thing to be remembered is that it has a propensity to recur (called as second crop) within 10-14 days. if this happens, you can start using the same medicine, but i suggest you get the kid evaluated with your pediatrician. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.                                                                                                                                                                                                                                                                                                                                                                                                                                                                              28\n",
              "hello, thank you for posting on chat doctor. it seems you are suffering from tina courts and corporal, a kind of fungal infection. i would suggest you to consult your dermatologist for proper management of the condition. i usually recommend proper course of oral antifungal chat doctor. you can additionally use antifungal dusting powder containing ketoconazole during daytime and a soap containing ketoconazole for rinsing of affected areas. take oral antihistamines for itching as required. maintain hygiene over those areas and avoid wearing tight undergarments. hope your queries are resolved and wish you best of health. kindly spare some time to rate my answer and                                                                                                                                                                                                                                                                                                                                                                                                                                        28\n",
              "hi... thank you for consulting in chat doctor. i think your kid is having habitual constipation. i have certain questions and suggestions for you. questions:1. did your kid pass motion or meconium on day one of life?2. since how long is the kid constipated?3. does the kid have any bleeding along with hard stools?4. how much milk does the kid consume per day?5. does the kid eat fruits and vegetables (fiber diet) appropriately? you can get back with answers at the following link - .com/doctors/ chat doctor. natural methods are the best to relieve constipation.2. constipation is a risk factor for uti3. maximum milk consumption per day should not exceed 300-400ml4. minimum 3-4 cups of fruits and vegetables to be consumed per day5. toilet training - that is - sitting in indian type of lavatory daily at the same time will help a lot. hope my answer was helpful for you. i am happy to help any time. further clarifications and consultations on chat doctor are welcome. if you do not have any clarifications, you can close the discussion and rate the answer. wish your kid good health.     24\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"response_clean\"].value_counts().head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePt8Gn4Sc953"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=[\"query_clean\"])  # Clean it now\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "executionInfo": {
          "elapsed": 52,
          "status": "ok",
          "timestamp": 1752907923449,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "AyNPsdsYdCzp",
        "outputId": "693a3264-9be7-4d2a-9bc5-9cdb37931c4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>query_clean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_clean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_sentences</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_tokens</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_tokens</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query_entities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_entities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_query_entities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_response_entities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has_entities</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "query_clean              0\n",
              "response_clean           0\n",
              "query_sentences          0\n",
              "response_sentences       0\n",
              "query_tokens             0\n",
              "response_tokens          0\n",
              "query_entities           0\n",
              "response_entities        0\n",
              "num_query_entities       0\n",
              "num_response_entities    0\n",
              "has_entities             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y4Mn2CQclxe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMCGsGwCclcY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcoqjWd8cml4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qKSiz1pcWNH"
      },
      "source": [
        "## **Installing Haystack Tool**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 54751,
          "status": "ok",
          "timestamp": 1755583872510,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "mYuOVdTANJNw",
        "outputId": "8ba1b34f-d93f-40f1-ac5f-388a854caddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m688.1/688.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for construct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.5/49.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m764.4/764.4 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m117.9/117.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "google-genai 1.30.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "langchain-core 0.3.74 requires pydantic>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\n",
            "gradio 5.42.0 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.0.0 which is incompatible.\n",
            "torchtune 0.6.1 requires Pillow>=9.4.0, but you have pillow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q haystack\n",
        "!pip install -q farm-haystack[colab]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 48983,
          "status": "ok",
          "timestamp": 1755583921513,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "FYJD3yV6XFCT",
        "outputId": "3d72d6a8-66b0-4b08-dfee-a570abf94c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Haystack BM25 is ready to use!\n"
          ]
        }
      ],
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "print(\" Haystack BM25 is ready to use!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 30853,
          "status": "ok",
          "timestamp": 1755583952365,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "wlA69sOjQ6vV",
        "outputId": "b5a529be-892b-4589-8f5c-366f7e7d5da4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.42.0 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.0.0 which is incompatible.\n",
            "torchtune 0.6.1 requires Pillow>=9.4.0, but you have pillow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn==1.3.2 --upgrade --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 16,
          "status": "ok",
          "timestamp": 1755583953816,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "s4EeBtwhR8LE",
        "outputId": "1f027558-dce1-4a74-96c7-9cf946db5a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Haystack BM25 is ready to use!\n"
          ]
        }
      ],
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "print(\" Haystack BM25 is ready to use!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st2WuYWwbXyO"
      },
      "source": [
        "## **Prerequisite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQpdLWj8Sp7N"
      },
      "outputs": [],
      "source": [
        "# Run this only once in a fresh runtime after installing haystack==1.18.0 and transformers==4.30.1\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.nodes import BM25Retriever\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC5ZvpgjbGr_"
      },
      "source": [
        "## **Step 1: Load the Cleaned Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sHy0sHBaZ-G"
      },
      "outputs": [],
      "source": [
        "# Drop rows with missing queries or responses (edge cases)\n",
        "df = df.dropna(subset=[\"query_clean\", \"response_clean\"])\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKreE-faanGG"
      },
      "source": [
        "## **Step 2: Convert to Haystack Document Format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 12751,
          "status": "ok",
          "timestamp": 1755583976345,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "FpE-hXprajSQ",
        "outputId": "86ad5d0b-a412-489b-d6b8-e0aba2e681d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Prepared 112164 documents for indexing.\n"
          ]
        }
      ],
      "source": [
        "# Haystack requires documents in this format:\n",
        "# {\"content\": <text>, \"meta\": {\"id\": <some_id>}}\n",
        "\n",
        "docs = [\n",
        "    {\"content\": row[\"response_clean\"], \"meta\": {\"id\": idx}}\n",
        "    for idx, row in df.iterrows()\n",
        "]\n",
        "\n",
        "print(f\" Prepared {len(docs)} documents for indexing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lMM0B6pcFwW"
      },
      "source": [
        "## **Step 3: Create an In-Memory BM25 Document Store**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 66711,
          "status": "ok",
          "timestamp": 1755584043054,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "KW1nGjyHb2lA",
        "outputId": "410e75bf-79c9-429c-fafa-26256ca8f337"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating BM25 representation...: 100%|| 110429/110429 [00:06<00:00, 16255.41 docs/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Indexed documents using BM25.\n"
          ]
        }
      ],
      "source": [
        "# Create an in-memory document store with BM25 enabled\n",
        "document_store = InMemoryDocumentStore(use_bm25=True)\n",
        "\n",
        "# Write documents into the store\n",
        "document_store.write_documents(docs)\n",
        "\n",
        "print(\" Indexed documents using BM25.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAcm7bu7c11b"
      },
      "source": [
        "## **Step 4: Initialize the BM25 Retriever**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2229,
          "status": "ok",
          "timestamp": 1755584045310,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "TR9iizQlcx50",
        "outputId": "f1991f20-d486-41e8-8115-2cdb539892d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Rank 1 (Document ID: 8399)\n",
            "tiredness and dizziness can be caused by low blood sugar/ low blood pressure/ or low hemoglobin (anemia). dizziness on waking up or sudden change in posture can be due to postural hypotension. coming to your query, nutritional deficiencies like iron/ vitaminb12/ folic acid. you can get a complete hologram to know if there is any problem with counts, also get your blood sugar and blood pressure che...\n",
            "------------------------------------------------------------\n",
            "\n",
            " Rank 2 (Document ID: 76565)\n",
            "the only way to keep your baby from waking up at nights is to delay his night feed when he wakes up, by up to 5-10 minutes each night, till he stops waking up. for example, if he wakes up at 1.05 am, let him wait till 1.10 before indulging his desire; the next night, let him wait for 10 minutes; the next, 15 minutes, and so on. gradually, he will stop waking up at night. it will be a tough 15 days...\n",
            "------------------------------------------------------------\n",
            "\n",
            " Rank 3 (Document ID: 86439)\n",
            "hello dear, i understand your concern. in my opinion dizziness is routinely seen in early pregnancy. it might be due to low he or anemia, low bp, low blood sugars. i suggest you to get he done to rule out anemia. take food in small quantities every 2 hourly like 3 meals and 2 snacks. as the fetus will be taking glucose continuously there will be decreasing sugars leading to dizziness. take adequat...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Create the retriever using the BM25 scoring function\n",
        "retriever = BM25Retriever(document_store=document_store)\n",
        "\n",
        "# Example query (from dataset or typed manually)\n",
        "query = \"what causes dizziness when waking up?\"\n",
        "\n",
        "# Retrieve top 3 documents\n",
        "top_k = 3\n",
        "results = retriever.retrieve(query=query, top_k=top_k)\n",
        "\n",
        "# Display results\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n Rank {i} (Document ID: {doc.meta['id']})\")\n",
        "    print(doc.content[:400] + \"...\")\n",
        "    print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 18,
          "status": "ok",
          "timestamp": 1755584200140,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "qwl8SXYlHavU",
        "outputId": "c328cd5c-8aee-43ec-c857-88b925cd782c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total valid queries in dataset: 112164\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total valid queries in dataset: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itmw4e1Q6DdI"
      },
      "source": [
        "## **bm25 Batch processing(for 50k data)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTR-F697IFri",
        "outputId": "b313dd08-ab8f-4172-904d-61da97b2d1f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 0-1000: 100%|| 1000/1000 [1:11:05<00:00,  4.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_0_1000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 1000-2000: 100%|| 1000/1000 [1:12:50<00:00,  4.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_1000_2000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 2000-3000: 100%|| 1000/1000 [1:12:59<00:00,  4.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_2000_3000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 3000-4000: 100%|| 1000/1000 [1:16:08<00:00,  4.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_3000_4000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 4000-5000: 100%|| 1000/1000 [1:11:02<00:00,  4.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_4000_5000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 5000-6000: 100%|| 1000/1000 [1:12:30<00:00,  4.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_5000_6000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 6000-7000: 100%|| 1000/1000 [1:09:39<00:00,  4.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_6000_7000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 7000-8000: 100%|| 1000/1000 [1:09:06<00:00,  4.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_7000_8000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 8000-9000: 100%|| 1000/1000 [1:09:24<00:00,  4.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_8000_9000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 9000-10000:  86%| | 863/1000 [59:49<11:22,  4.98s/it]"
          ]
        }
      ],
      "source": [
        "start_idx = 0  # change to last saved + 1\n",
        "batch_size = 1000\n",
        "output_base_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "\n",
        "# Ensure save dir exists\n",
        "import os\n",
        "os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "for i in range(start_idx, len(selected_df), batch_size):\n",
        "    batch_df = selected_df.iloc[i:i+batch_size]\n",
        "    output_file = f\"{output_base_path}/bm25_batch_{i}_{i+len(batch_df)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping existing batch  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing {i}-{i+len(batch_df)}\"):\n",
        "        query = row[\"query_clean\"]\n",
        "        top_docs = retriever.retrieve(query=query, top_k=3)\n",
        "        for rank, doc in enumerate(top_docs, 1):\n",
        "            rows.append({\n",
        "                \"query\": query,\n",
        "                \"rank\": rank,\n",
        "                \"doc_id\": doc.meta[\"id\"],\n",
        "                \"response\": doc.content\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved batch  {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d83YdWkScJGa",
        "outputId": "90fef5cc-209a-4189-c939-eed46f037179"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 9000-10000: 100%|| 1000/1000 [1:05:40<00:00,  3.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_9000_10000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 10000-11000: 100%|| 1000/1000 [1:07:23<00:00,  4.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_10000_11000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 11000-12000: 100%|| 1000/1000 [1:07:01<00:00,  4.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_11000_12000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 12000-13000:  97%|| 969/1000 [1:07:17<02:29,  4.81s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "#  Load your dataset again\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#  Select the first N rows (adjust N as needed)\n",
        "N = 56082\n",
        "selected_df = df.iloc[:N]\n",
        "\n",
        "#  Initialize BM25 retriever again\n",
        "retriever = BM25Retriever(document_store=document_store)  # make sure document_store is loaded\n",
        "\n",
        "#  Resume parameters\n",
        "start_idx = 9000  # set this to where it stopped\n",
        "batch_size = 1000\n",
        "output_base_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "#  Resume loop\n",
        "for i in range(start_idx, len(selected_df), batch_size):\n",
        "    batch_df = selected_df.iloc[i:i+batch_size]\n",
        "    output_file = f\"{output_base_path}/bm25_batch_{i}_{i+len(batch_df)}.csv\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping existing batch  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing {i}-{i+len(batch_df)}\"):\n",
        "        query = row[\"query_clean\"]\n",
        "        top_docs = retriever.retrieve(query=query, top_k=3)\n",
        "        for rank, doc in enumerate(top_docs, 1):\n",
        "            rows.append({\n",
        "                \"query\": query,\n",
        "                \"rank\": rank,\n",
        "                \"doc_id\": doc.meta[\"id\"],\n",
        "                \"response\": doc.content\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved batch  {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4LNEhwUcI8R",
        "outputId": "c9a3765f-1813-4127-b06d-c99cdd24123d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 12000-13000: 100%|| 1000/1000 [1:17:57<00:00,  4.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_12000_13000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 13000-14000: 100%|| 1000/1000 [1:19:16<00:00,  4.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_13000_14000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 14000-15000: 100%|| 1000/1000 [1:13:11<00:00,  4.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_14000_15000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 15000-16000: 100%|| 1000/1000 [1:12:39<00:00,  4.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_15000_16000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 16000-17000: 100%|| 1000/1000 [1:16:21<00:00,  4.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_16000_17000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 17000-18000: 100%|| 1000/1000 [1:14:47<00:00,  4.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_17000_18000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 18000-19000: 100%|| 1000/1000 [1:10:54<00:00,  4.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_18000_19000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 19000-20000: 100%|| 1000/1000 [1:09:36<00:00,  4.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_19000_20000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 20000-21000: 100%|| 1000/1000 [1:09:28<00:00,  4.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_20000_21000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 21000-22000:  48%|     | 484/1000 [36:36<44:45,  5.20s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "#  Load your dataset again\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#  Select the first N rows (adjust N as needed)\n",
        "N = 56082\n",
        "selected_df = df.iloc[:N]\n",
        "\n",
        "#  Initialize BM25 retriever again\n",
        "retriever = BM25Retriever(document_store=document_store)  # make sure document_store is loaded\n",
        "\n",
        "#  Resume parameters\n",
        "start_idx = 12000  # set this to where it stopped\n",
        "batch_size = 1000\n",
        "output_base_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "#  Resume loop\n",
        "for i in range(start_idx, len(selected_df), batch_size):\n",
        "    batch_df = selected_df.iloc[i:i+batch_size]\n",
        "    output_file = f\"{output_base_path}/bm25_batch_{i}_{i+len(batch_df)}.csv\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping existing batch  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing {i}-{i+len(batch_df)}\"):\n",
        "        query = row[\"query_clean\"]\n",
        "        top_docs = retriever.retrieve(query=query, top_k=3)\n",
        "        for rank, doc in enumerate(top_docs, 1):\n",
        "            rows.append({\n",
        "                \"query\": query,\n",
        "                \"rank\": rank,\n",
        "                \"doc_id\": doc.meta[\"id\"],\n",
        "                \"response\": doc.content\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved batch  {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyB1FjKldFYy",
        "outputId": "ac3406c2-ca6e-4621-ebec-a876f960414a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 21000-22000: 100%|| 1000/1000 [1:17:49<00:00,  4.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_21000_22000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 22000-23000: 100%|| 1000/1000 [1:19:29<00:00,  4.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_22000_23000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 23000-24000: 100%|| 1000/1000 [1:17:35<00:00,  4.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_23000_24000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 24000-25000: 100%|| 1000/1000 [1:18:02<00:00,  4.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_24000_25000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 25000-26000: 100%|| 1000/1000 [1:17:59<00:00,  4.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_25000_26000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 26000-27000: 100%|| 1000/1000 [1:19:01<00:00,  4.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_26000_27000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 27000-28000: 100%|| 1000/1000 [1:18:47<00:00,  4.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_27000_28000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 28000-29000: 100%|| 1000/1000 [1:17:20<00:00,  4.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_28000_29000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 29000-30000:  96%|| 963/1000 [1:14:29<02:12,  3.57s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "#  Load your dataset again\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#  Select the first N rows (adjust N as needed)\n",
        "N = 56082\n",
        "selected_df = df.iloc[:N]\n",
        "\n",
        "#  Initialize BM25 retriever again\n",
        "retriever = BM25Retriever(document_store=document_store)  # make sure document_store is loaded\n",
        "\n",
        "#  Resume parameters\n",
        "start_idx = 21000  # set this to where it stopped\n",
        "batch_size = 1000\n",
        "output_base_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "#  Resume loop\n",
        "for i in range(start_idx, len(selected_df), batch_size):\n",
        "    batch_df = selected_df.iloc[i:i+batch_size]\n",
        "    output_file = f\"{output_base_path}/bm25_batch_{i}_{i+len(batch_df)}.csv\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping existing batch  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing {i}-{i+len(batch_df)}\"):\n",
        "        query = row[\"query_clean\"]\n",
        "        top_docs = retriever.retrieve(query=query, top_k=3)\n",
        "        for rank, doc in enumerate(top_docs, 1):\n",
        "            rows.append({\n",
        "                \"query\": query,\n",
        "                \"rank\": rank,\n",
        "                \"doc_id\": doc.meta[\"id\"],\n",
        "                \"response\": doc.content\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved batch  {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPo-46EOEDyx",
        "outputId": "d4e54659-dea1-41e1-ea9b-e22fb60b7f0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 29000-30000: 100%|| 1000/1000 [1:10:00<00:00,  4.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_29000_30000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 30000-31000: 100%|| 1000/1000 [1:10:29<00:00,  4.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_30000_31000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 31000-32000: 100%|| 1000/1000 [1:12:06<00:00,  4.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_31000_32000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 32000-33000: 100%|| 1000/1000 [1:11:06<00:00,  4.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_32000_33000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 33000-34000: 100%|| 1000/1000 [1:08:49<00:00,  4.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_33000_34000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 34000-35000: 100%|| 1000/1000 [1:09:59<00:00,  4.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_34000_35000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 35000-36000: 100%|| 1000/1000 [1:10:29<00:00,  4.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_35000_36000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 36000-37000: 100%|| 1000/1000 [1:09:58<00:00,  4.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_36000_37000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 37000-38000: 100%|| 1000/1000 [1:09:04<00:00,  4.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_37000_38000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 38000-39000:  85%| | 850/1000 [1:00:34<08:33,  3.42s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "#  Load your dataset again\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#  Select the first N rows (adjust N as needed)\n",
        "N = 56082\n",
        "selected_df = df.iloc[:N]\n",
        "\n",
        "#  Initialize BM25 retriever again\n",
        "retriever = BM25Retriever(document_store=document_store)  # make sure document_store is loaded\n",
        "\n",
        "#  Resume parameters\n",
        "start_idx = 29000  # set this to where it stopped\n",
        "batch_size = 1000\n",
        "output_base_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "#  Resume loop\n",
        "for i in range(start_idx, len(selected_df), batch_size):\n",
        "    batch_df = selected_df.iloc[i:i+batch_size]\n",
        "    output_file = f\"{output_base_path}/bm25_batch_{i}_{i+len(batch_df)}.csv\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping existing batch  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing {i}-{i+len(batch_df)}\"):\n",
        "        query = row[\"query_clean\"]\n",
        "        top_docs = retriever.retrieve(query=query, top_k=3)\n",
        "        for rank, doc in enumerate(top_docs, 1):\n",
        "            rows.append({\n",
        "                \"query\": query,\n",
        "                \"rank\": rank,\n",
        "                \"doc_id\": doc.meta[\"id\"],\n",
        "                \"response\": doc.content\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved batch  {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CKVM6LaEZo8",
        "outputId": "329a344c-6001-4777-c3e2-0749661942fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 38000-39000: 100%|| 1000/1000 [1:13:32<00:00,  4.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_38000_39000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 39000-40000: 100%|| 1000/1000 [1:11:06<00:00,  4.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_39000_40000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 40000-41000: 100%|| 1000/1000 [1:12:12<00:00,  4.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_40000_41000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 41000-42000: 100%|| 1000/1000 [1:12:31<00:00,  4.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_41000_42000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 42000-43000: 100%|| 1000/1000 [1:10:32<00:00,  4.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_42000_43000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 43000-44000: 100%|| 1000/1000 [1:13:29<00:00,  4.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_43000_44000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 44000-45000: 100%|| 1000/1000 [1:10:44<00:00,  4.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_44000_45000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 45000-46000: 100%|| 1000/1000 [1:14:39<00:00,  4.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_45000_46000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 46000-47000: 100%|| 1000/1000 [1:12:23<00:00,  4.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_46000_47000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 47000-48000:  12%|        | 124/1000 [08:53<1:05:51,  4.51s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "#  Load your dataset again\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#  Select the first N rows (adjust N as needed)\n",
        "N = 56082\n",
        "selected_df = df.iloc[:N]\n",
        "\n",
        "#  Initialize BM25 retriever again\n",
        "retriever = BM25Retriever(document_store=document_store)  # make sure document_store is loaded\n",
        "\n",
        "#  Resume parameters\n",
        "start_idx = 38000  # set this to where it stopped\n",
        "batch_size = 1000\n",
        "output_base_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "#  Resume loop\n",
        "for i in range(start_idx, len(selected_df), batch_size):\n",
        "    batch_df = selected_df.iloc[i:i+batch_size]\n",
        "    output_file = f\"{output_base_path}/bm25_batch_{i}_{i+len(batch_df)}.csv\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping existing batch  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing {i}-{i+len(batch_df)}\"):\n",
        "        query = row[\"query_clean\"]\n",
        "        top_docs = retriever.retrieve(query=query, top_k=3)\n",
        "        for rank, doc in enumerate(top_docs, 1):\n",
        "            rows.append({\n",
        "                \"query\": query,\n",
        "                \"rank\": rank,\n",
        "                \"doc_id\": doc.meta[\"id\"],\n",
        "                \"response\": doc.content\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved batch  {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IGzAP2fCf74",
        "outputId": "1f9f9b0a-3013-41c1-ab75-8a35913b2f25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 47000-48000: 100%|| 1000/1000 [1:48:26<00:00,  6.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_47000_48000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 48000-49000: 100%|| 1000/1000 [1:51:56<00:00,  6.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_48000_49000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 49000-50000: 100%|| 1000/1000 [1:44:07<00:00,  6.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved batch  /content/drive/MyDrive/bm25_batches/bm25_batch_49000_50000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing 50000-51000:  94%|| 938/1000 [1:37:37<05:09,  4.99s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "#  Load your dataset again\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#  Select the first N rows (adjust N as needed)\n",
        "N = 56082\n",
        "selected_df = df.iloc[:N]\n",
        "\n",
        "#  Initialize BM25 retriever again\n",
        "retriever = BM25Retriever(document_store=document_store)  # make sure document_store is loaded\n",
        "\n",
        "#  Resume parameters\n",
        "start_idx = 47000  # set this to where it stopped\n",
        "batch_size = 1000\n",
        "output_base_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "os.makedirs(output_base_path, exist_ok=True)\n",
        "\n",
        "#  Resume loop\n",
        "for i in range(start_idx, len(selected_df), batch_size):\n",
        "    batch_df = selected_df.iloc[i:i+batch_size]\n",
        "    output_file = f\"{output_base_path}/bm25_batch_{i}_{i+len(batch_df)}.csv\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping existing batch  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing {i}-{i+len(batch_df)}\"):\n",
        "        query = row[\"query_clean\"]\n",
        "        top_docs = retriever.retrieve(query=query, top_k=3)\n",
        "        for rank, doc in enumerate(top_docs, 1):\n",
        "            rows.append({\n",
        "                \"query\": query,\n",
        "                \"rank\": rank,\n",
        "                \"doc_id\": doc.meta[\"id\"],\n",
        "                \"response\": doc.content\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved batch  {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 28739,
          "status": "ok",
          "timestamp": 1755616988303,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "DpHvEV946X2d",
        "outputId": "c0d01e2c-1e57-4621-f2fe-14875a6df3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Found 51 batch files\n",
            " Merged CSV saved to: /content/drive/MyDrive/bm25_merged_results.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# Path to batch folder\n",
        "batch_path = \"/content/drive/MyDrive/bm25_batches\"\n",
        "\n",
        "# Match your actual file names\n",
        "batch_files = glob.glob(os.path.join(batch_path, \"bm25_batch_*.csv\"))\n",
        "batch_files.sort()  # ensure correct order\n",
        "\n",
        "print(f\" Found {len(batch_files)} batch files\")\n",
        "\n",
        "if batch_files:\n",
        "    dfs = [pd.read_csv(f) for f in batch_files]\n",
        "    merged_df = pd.concat(dfs, ignore_index=True)\n",
        "    output_file = \"/content/drive/MyDrive/bm25_merged_results.csv\"\n",
        "    merged_df.to_csv(output_file, index=False)\n",
        "    print(f\" Merged CSV saved to: {output_file}\")\n",
        "else:\n",
        "    print(\" No valid CSV files found to merge.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdN_KDCWFfSB"
      },
      "source": [
        "## **Load libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 15715,
          "status": "ok",
          "timestamp": 1755617866355,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "ZTbC7JvIInbV",
        "outputId": "3787547d-7b0f-42ae-b62f-5a50659115f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "#  Load dataset\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/cleaned_and_tokenized_and_entity-defined_healthcaremagic.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "corpus = df[\"response_clean\"].dropna().tolist()\n",
        "\n",
        "#  Load Contriever model + tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/contriever\")\n",
        "model = AutoModel.from_pretrained(\"facebook/contriever\")\n",
        "model.eval()  # CPU only\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shozogx1w0z1"
      },
      "source": [
        "## **A.Basic Rag Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSco2EmnxO72"
      },
      "source": [
        "### **1)Load & sanity-check the merged file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "executionInfo": {
          "elapsed": 6863,
          "status": "ok",
          "timestamp": 1758034616485,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "6We_L4jpxDMD",
        "outputId": "5c1feb80-6a63-41e5-975f-56fc549c8aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 153000\n",
            "Columns: ['query', 'rank', 'doc_id', 'response']\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfm"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f85678d5-a792-4b73-b6c7-46a71140829f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>rank</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a woke up this morning feeling the whole room ...</td>\n",
              "      <td>1</td>\n",
              "      <td>77258</td>\n",
              "      <td>hello, and i hope i can help you today. the se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a woke up this morning feeling the whole room ...</td>\n",
              "      <td>2</td>\n",
              "      <td>24083</td>\n",
              "      <td>his have gone through your complaints. you are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a woke up this morning feeling the whole room ...</td>\n",
              "      <td>3</td>\n",
              "      <td>83451</td>\n",
              "      <td>hi and thank you so much for this query. i am ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f85678d5-a792-4b73-b6c7-46a71140829f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f85678d5-a792-4b73-b6c7-46a71140829f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f85678d5-a792-4b73-b6c7-46a71140829f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-af91b9e3-d884-4a36-97eb-8ecd6480a76d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af91b9e3-d884-4a36-97eb-8ecd6480a76d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-af91b9e3-d884-4a36-97eb-8ecd6480a76d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               query  rank  doc_id  \\\n",
              "0  a woke up this morning feeling the whole room ...     1   77258   \n",
              "1  a woke up this morning feeling the whole room ...     2   24083   \n",
              "2  a woke up this morning feeling the whole room ...     3   83451   \n",
              "\n",
              "                                            response  \n",
              "0  hello, and i hope i can help you today. the se...  \n",
              "1  his have gone through your complaints. you are...  \n",
              "2  hi and thank you so much for this query. i am ...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "MERGED_PATH = \"/content/drive/MyDrive/bm25_merged_results.csv\"\n",
        "dfm = pd.read_csv(MERGED_PATH)\n",
        "\n",
        "print(\"Rows:\", len(dfm))\n",
        "print(\"Columns:\", list(dfm.columns))\n",
        "dfm.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOI0SWscxVcj"
      },
      "source": [
        "### **2) Basic cleaning & de-duplication**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "executionInfo": {
          "elapsed": 692,
          "status": "ok",
          "timestamp": 1758034617995,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "OzLCf0zvxLgR",
        "outputId": "b58a5105-d801-4eb4-a633-f6e23b95ebbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After clean: (152973, 4)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfm"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7d8778fa-24e9-4495-889f-9aeabb525cdd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>rank</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a woke up this morning feeling the whole room ...</td>\n",
              "      <td>1</td>\n",
              "      <td>77258</td>\n",
              "      <td>hello, and i hope i can help you today. the se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a woke up this morning feeling the whole room ...</td>\n",
              "      <td>2</td>\n",
              "      <td>24083</td>\n",
              "      <td>his have gone through your complaints. you are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a woke up this morning feeling the whole room ...</td>\n",
              "      <td>3</td>\n",
              "      <td>83451</td>\n",
              "      <td>hi and thank you so much for this query. i am ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d8778fa-24e9-4495-889f-9aeabb525cdd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d8778fa-24e9-4495-889f-9aeabb525cdd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d8778fa-24e9-4495-889f-9aeabb525cdd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-688e821e-de7f-429e-809c-48aba843f3a4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-688e821e-de7f-429e-809c-48aba843f3a4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-688e821e-de7f-429e-809c-48aba843f3a4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               query  rank  doc_id  \\\n",
              "0  a woke up this morning feeling the whole room ...     1   77258   \n",
              "1  a woke up this morning feeling the whole room ...     2   24083   \n",
              "2  a woke up this morning feeling the whole room ...     3   83451   \n",
              "\n",
              "                                            response  \n",
              "0  hello, and i hope i can help you today. the se...  \n",
              "1  his have gone through your complaints. you are...  \n",
              "2  hi and thank you so much for this query. i am ...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop empties and duplicates\n",
        "dfm = dfm.dropna(subset=[\"query\", \"response\"])\n",
        "dfm = dfm.drop_duplicates(subset=[\"query\", \"response\"]).reset_index(drop=True)\n",
        "\n",
        "# Ensure rank is int\n",
        "if \"rank\" in dfm.columns:\n",
        "    dfm[\"rank\"] = pd.to_numeric(dfm[\"rank\"], errors=\"coerce\").fillna(999999).astype(int)\n",
        "\n",
        "print(\"After clean:\", dfm.shape)\n",
        "dfm.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYeVumTmx55R"
      },
      "source": [
        "### **3) Convert to per-query candidate lists (top-k)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2365,
          "status": "ok",
          "timestamp": 1758034622530,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "ERn35p3Wx9L3",
        "outputId": "6d26f8be-a1a5-4356-91f1-6435e9dc200e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3,\n",
              " ['hello and welcome to chat doctor, an elevated white blood cell counts occurs in case of infection. and amongst white blood cells, the neutrophils are increased. thus, high neutrophils suggest bacterial infection. you need to consult your primary healthcare provider for clinical assessment and treatment of bacterial infection. the focus of bacterial infection has also to be found out. thanks and take care chat doctor.',\n",
              "  'hi!welcome to chat doctor .com. there are several possible causes for a high white blood cell count/leukocytosis:physical stress (e.g., from seizures, anesthesia or overexertion) and emotional stress can also elevate white blood cell counts. medications commonly associated with leukocytosis include corticosteroids, lithium and beta agonists. increased eosinophil or basophil counts, resulting from a variety of infections, allergic reactions and other causes, can lead to leukocytosis in some patients. primary bone marrow disorders. investigation should include differential leukocyte count which tells which wbc is high, platelet count, hb, bone marrow aspiration and biopsy to rule out leukemia. all the best.'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TOPK = 5  # change as you like\n",
        "\n",
        "if \"rank\" in dfm.columns:\n",
        "    dfm = dfm.sort_values([\"query\", \"rank\"])\n",
        "else:\n",
        "    # If rank missing, keep first TOPK per query in file order\n",
        "    dfm[\"rank\"] = dfm.groupby(\"query\").cumcount() + 1\n",
        "\n",
        "candidates_by_query = (\n",
        "    dfm.groupby(\"query\")[\"response\"]\n",
        "       .apply(lambda s: list(s.head(TOPK)))\n",
        "       .to_dict()\n",
        ")\n",
        "\n",
        "# Quick peek\n",
        "sample_q = next(iter(candidates_by_query))\n",
        "len(candidates_by_query[sample_q]), candidates_by_query[sample_q][:2]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdNX2vhoH4PC"
      },
      "source": [
        "### **4) Re-rank BM25 candidates with a Sentence-Transformers CrossEncoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siGDFeW2uYle"
      },
      "source": [
        "### Step 1: Install & Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCvRq62QuASq"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers\n",
        "\n",
        "from sentence_transformers import CrossEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97XzRQ_4ucMT"
      },
      "source": [
        "### Step 2: Load candidates_by_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 10554,
          "status": "ok",
          "timestamp": 1758034677514,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "Zt9LwaFYuD-k",
        "outputId": "d054a9dc-51a0-4e33-f143-0924bcad827d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total queries: 50991\n"
          ]
        }
      ],
      "source": [
        "# If you saved merged BM25 results earlier\n",
        "df_merged = pd.read_csv(\"/content/drive/MyDrive/bm25_merged_results.csv\")\n",
        "\n",
        "# Ensure sorted by BM25 rank (if exists)\n",
        "if \"rank\" in df_merged.columns:\n",
        "    df_merged = df_merged.sort_values([\"query\", \"rank\"])\n",
        "else:\n",
        "    df_merged[\"rank\"] = df_merged.groupby(\"query\").cumcount() + 1\n",
        "\n",
        "# Group into dict: query -> list of responses\n",
        "candidates_by_query = (\n",
        "    df_merged.groupby(\"query\")[\"response\"]\n",
        "             .apply(lambda s: list(s.head(10)))  # Top 10 candidates per query\n",
        "             .to_dict()\n",
        ")\n",
        "\n",
        "print(\"Total queries:\", len(candidates_by_query))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK8E0Bm8ujWG"
      },
      "source": [
        "### Step 3: Initialize the CrossEncoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "executionInfo": {
          "elapsed": 4852,
          "status": "ok",
          "timestamp": 1758034682369,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "G9u66MVcuHJ-",
        "outputId": "a54b1dcb-761d-42b3-9cb4-b2e42292b3ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87547a3a9b3c4c6aa23991f47863030f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abc275190b1349d4ba7528925b9572f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16c9cc692f404f58aac821653c306787",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dc3935efd2c4fce8f8f437b44c0659f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a3821af8a4a494ba214bb1f31c85844",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73ce345919b447a38b6ff3f9d9103fa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73ee7562471d4a6485fae451d69797d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Reranker loaded\n"
          ]
        }
      ],
      "source": [
        "RERANKER = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "ce = CrossEncoder(RERANKER)\n",
        "print(\" Reranker loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tIpvFmiusAI"
      },
      "source": [
        "### Step 4: Define re-ranking function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn4_2Ul3uyjj"
      },
      "outputs": [],
      "source": [
        "def rerank_candidates(query: str, responses: list, top_k=3):\n",
        "    if not responses:\n",
        "        return []\n",
        "    pairs = [(query, r) for r in responses]\n",
        "    scores = ce.predict(pairs)\n",
        "    order = np.argsort(scores)[::-1][:top_k]\n",
        "    return [(responses[i], float(scores[i])) for i in order]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M43sSxh9u4pM"
      },
      "source": [
        "### Step 5: Process in batches and SAVE each batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZKJgmhzwcD2",
        "outputId": "58998bc9-f84a-4b9d-bb35-69496342484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 0-1000: 100%|| 1000/1000 [10:42<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_0_1000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 1000-2000: 100%|| 1000/1000 [10:54<00:00,  1.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_1000_2000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 2000-3000: 100%|| 1000/1000 [11:08<00:00,  1.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_2000_3000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 3000-4000: 100%|| 1000/1000 [10:38<00:00,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_3000_4000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 4000-5000: 100%|| 1000/1000 [10:28<00:00,  1.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_4000_5000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 5000-6000: 100%|| 1000/1000 [10:10<00:00,  1.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_5000_6000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 6000-7000: 100%|| 1000/1000 [10:16<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_6000_7000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 7000-8000: 100%|| 1000/1000 [09:53<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_7000_8000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 8000-9000: 100%|| 1000/1000 [10:38<00:00,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_8000_9000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 9000-10000: 100%|| 1000/1000 [10:38<00:00,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_9000_10000.csv\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 10_000, batch_size):  # 10k limit\n",
        "    batch_queries = all_queries[i:i+batch_size]\n",
        "    output_file = f\"{output_dir}/reranked_{i}_{i+len(batch_queries)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping already done  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for q in tqdm(batch_queries, desc=f\"Re-ranking {i}-{i+len(batch_queries)}\"):\n",
        "        responses = candidates_by_query.get(q, [])\n",
        "        if not responses: continue  # skip empty\n",
        "        top = rerank_candidates(q, responses, top_k=3)\n",
        "        for rank, (resp, score) in enumerate(top, 1):\n",
        "            rows.append({\n",
        "                \"query\": q,\n",
        "                \"rank\": rank,\n",
        "                \"response\": resp,\n",
        "                \"rerank_score\": score\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 48,
          "status": "ok",
          "timestamp": 1758034858432,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "NFY0R-htDY22",
        "outputId": "ba0cffff-fd0d-4cd2-f2d1-525e5c19d65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Total queries in dict: 50991\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1000\n",
        "\n",
        "# Rebuild this if it's not defined yet\n",
        "all_queries = list(candidates_by_query.keys())\n",
        "\n",
        "print(f\" Total queries in dict: {len(all_queries)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpusntqoD5dk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/rerank_batches\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3651647,
          "status": "ok",
          "timestamp": 1757099800347,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "jXuTvONeCm5B",
        "outputId": "a998db05-190b-4ca8-d335-4fef1a74c214"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 10000-11000: 100%|| 1000/1000 [07:05<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_10000_11000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 11000-12000: 100%|| 1000/1000 [06:32<00:00,  2.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_11000_12000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 12000-13000: 100%|| 1000/1000 [06:42<00:00,  2.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_12000_13000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 13000-14000: 100%|| 1000/1000 [06:40<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_13000_14000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 14000-15000: 100%|| 1000/1000 [06:37<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_14000_15000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 15000-16000: 100%|| 1000/1000 [06:39<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_15000_16000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 16000-17000: 100%|| 1000/1000 [06:38<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_16000_17000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 17000-18000: 100%|| 1000/1000 [07:43<00:00,  2.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_17000_18000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 18000-19000: 100%|| 1000/1000 [07:26<00:00,  2.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_18000_19000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 19000-20000: 100%|| 1000/1000 [07:10<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_19000_20000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10_000, 20000, batch_size):  # 10k to 20k\n",
        "    batch_queries = all_queries[i:i+batch_size]\n",
        "    output_file = f\"{output_dir}/reranked_{i}_{i+len(batch_queries)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping already done  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for q in tqdm(batch_queries, desc=f\"Re-ranking {i}-{i+len(batch_queries)}\"):\n",
        "        responses = candidates_by_query.get(q, [])\n",
        "        if not responses:\n",
        "            continue\n",
        "        top = rerank_candidates(q, responses, top_k=3)\n",
        "        for rank, (resp, score) in enumerate(top, 1):\n",
        "            rows.append({\n",
        "                \"query\": q,\n",
        "                \"rank\": rank,\n",
        "                \"response\": resp,\n",
        "                \"rerank_score\": score\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnAB0z5zzNgS",
        "outputId": "b9a9b3aa-da53-4155-8caf-f04ebb0b11a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 20000-21000: 100%|| 1000/1000 [07:07<00:00,  2.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_20000_21000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 21000-22000: 100%|| 1000/1000 [06:37<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_21000_22000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 22000-23000: 100%|| 1000/1000 [06:50<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_22000_23000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 23000-24000: 100%|| 1000/1000 [07:06<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_23000_24000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 24000-25000: 100%|| 1000/1000 [07:12<00:00,  2.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_24000_25000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 25000-26000: 100%|| 1000/1000 [06:57<00:00,  2.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_25000_26000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 26000-27000: 100%|| 1000/1000 [07:01<00:00,  2.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_26000_27000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 27000-28000: 100%|| 1000/1000 [06:45<00:00,  2.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_27000_28000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 28000-29000: 100%|| 1000/1000 [06:50<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_28000_29000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 29000-30000: 100%|| 1000/1000 [06:49<00:00,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_29000_30000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(20000, 30000, batch_size):  # 10k to 20k\n",
        "    batch_queries = all_queries[i:i+batch_size]\n",
        "    output_file = f\"{output_dir}/reranked_{i}_{i+len(batch_queries)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping already done  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for q in tqdm(batch_queries, desc=f\"Re-ranking {i}-{i+len(batch_queries)}\"):\n",
        "        responses = candidates_by_query.get(q, [])\n",
        "        if not responses:\n",
        "            continue\n",
        "        top = rerank_candidates(q, responses, top_k=3)\n",
        "        for rank, (resp, score) in enumerate(top, 1):\n",
        "            rows.append({\n",
        "                \"query\": q,\n",
        "                \"rank\": rank,\n",
        "                \"response\": resp,\n",
        "                \"rerank_score\": score\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQxdo0GtZc1d",
        "outputId": "0853ee4e-eea9-4446-d5b2-459e591ff3a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 30000-31000: 100%|| 1000/1000 [10:29<00:00,  1.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_30000_31000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 31000-32000: 100%|| 1000/1000 [10:47<00:00,  1.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_31000_32000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 32000-33000: 100%|| 1000/1000 [10:16<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_32000_33000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 33000-34000: 100%|| 1000/1000 [10:20<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_33000_34000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 34000-35000: 100%|| 1000/1000 [10:22<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_34000_35000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 35000-36000: 100%|| 1000/1000 [10:31<00:00,  1.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_35000_36000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 36000-37000: 100%|| 1000/1000 [10:02<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_36000_37000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 37000-38000: 100%|| 1000/1000 [09:53<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_37000_38000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 38000-39000: 100%|| 1000/1000 [10:02<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_38000_39000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 39000-40000:  39%|      | 394/1000 [03:47<04:33,  2.21it/s]"
          ]
        }
      ],
      "source": [
        "for i in range(30000, 40000, batch_size):  # 10k to 20k\n",
        "    batch_queries = all_queries[i:i+batch_size]\n",
        "    output_file = f\"{output_dir}/reranked_{i}_{i+len(batch_queries)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping already done  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for q in tqdm(batch_queries, desc=f\"Re-ranking {i}-{i+len(batch_queries)}\"):\n",
        "        responses = candidates_by_query.get(q, [])\n",
        "        if not responses:\n",
        "            continue\n",
        "        top = rerank_candidates(q, responses, top_k=3)\n",
        "        for rank, (resp, score) in enumerate(top, 1):\n",
        "            rows.append({\n",
        "                \"query\": q,\n",
        "                \"rank\": rank,\n",
        "                \"response\": resp,\n",
        "                \"rerank_score\": score\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYfr_Hm8HvRO",
        "outputId": "5140a4e8-b3f5-458e-e3e4-f8ea0c44d02b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 40000-41000: 100%|| 1000/1000 [11:07<00:00,  1.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_40000_41000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 41000-42000: 100%|| 1000/1000 [10:19<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_41000_42000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 42000-43000: 100%|| 1000/1000 [10:20<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_42000_43000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 43000-44000: 100%|| 1000/1000 [10:00<00:00,  1.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_43000_44000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 44000-45000: 100%|| 1000/1000 [09:43<00:00,  1.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_44000_45000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 45000-46000: 100%|| 1000/1000 [09:50<00:00,  1.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_45000_46000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 46000-47000: 100%|| 1000/1000 [10:17<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/rerank_batches/reranked_46000_47000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Re-ranking 47000-48000:  60%|    | 598/1000 [06:01<04:06,  1.63it/s]"
          ]
        }
      ],
      "source": [
        "for i in range(40000, 50000, batch_size):  # 10k to 20k\n",
        "    batch_queries = all_queries[i:i+batch_size]\n",
        "    output_file = f\"{output_dir}/reranked_{i}_{i+len(batch_queries)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping already done  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for q in tqdm(batch_queries, desc=f\"Re-ranking {i}-{i+len(batch_queries)}\"):\n",
        "        responses = candidates_by_query.get(q, [])\n",
        "        if not responses:\n",
        "            continue\n",
        "        top = rerank_candidates(q, responses, top_k=3)\n",
        "        for rank, (resp, score) in enumerate(top, 1):\n",
        "            rows.append({\n",
        "                \"query\": q,\n",
        "                \"rank\": rank,\n",
        "                \"response\": resp,\n",
        "                \"rerank_score\": score\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 22,
          "status": "ok",
          "timestamp": 1758034867914,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "hbrPR_LsCOO2",
        "outputId": "257dc1d5-c580-4311-d6eb-d4d43b15518c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Skipping already done  /content/drive/MyDrive/rerank_batches/reranked_39000_40000.csv\n"
          ]
        }
      ],
      "source": [
        "for i in range(39000, 40000, batch_size):  # 10k limit\n",
        "    batch_queries = all_queries[i:i+batch_size]\n",
        "    output_file = f\"{output_dir}/reranked_{i}_{i+len(batch_queries)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping already done  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for q in tqdm(batch_queries, desc=f\"Re-ranking {i}-{i+len(batch_queries)}\"):\n",
        "        responses = candidates_by_query.get(q, [])\n",
        "        if not responses: continue  # skip empty\n",
        "        top = rerank_candidates(q, responses, top_k=3)\n",
        "        for rank, (resp, score) in enumerate(top, 1):\n",
        "            rows.append({\n",
        "                \"query\": q,\n",
        "                \"rank\": rank,\n",
        "                \"response\": resp,\n",
        "                \"rerank_score\": score\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 18,
          "status": "ok",
          "timestamp": 1758034913359,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "LtcIYSwiC1F4",
        "outputId": "9d2f3c16-f041-4ef7-990d-9a6f0493c72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Skipping already done  /content/drive/MyDrive/rerank_batches/reranked_47000_48000.csv\n",
            " Skipping already done  /content/drive/MyDrive/rerank_batches/reranked_48000_49000.csv\n",
            " Skipping already done  /content/drive/MyDrive/rerank_batches/reranked_49000_50000.csv\n"
          ]
        }
      ],
      "source": [
        "for i in range(47000, 50000, batch_size):  # 10k limit\n",
        "    batch_queries = all_queries[i:i+batch_size]\n",
        "    output_file = f\"{output_dir}/reranked_{i}_{i+len(batch_queries)}.csv\"\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\" Skipping already done  {output_file}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for q in tqdm(batch_queries, desc=f\"Re-ranking {i}-{i+len(batch_queries)}\"):\n",
        "        responses = candidates_by_query.get(q, [])\n",
        "        if not responses: continue  # skip empty\n",
        "        top = rerank_candidates(q, responses, top_k=3)\n",
        "        for rank, (resp, score) in enumerate(top, 1):\n",
        "            rows.append({\n",
        "                \"query\": q,\n",
        "                \"rank\": rank,\n",
        "                \"response\": resp,\n",
        "                \"rerank_score\": score\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
        "    print(f\" Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 30061,
          "status": "ok",
          "timestamp": 1758035564678,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "id4AHLskE4D6",
        "outputId": "84c9534c-f330-40c0-c01c-6f5e804c6669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Found 50 batch files.\n",
            " Merged all batches: (150000, 4)\n",
            " Final merged file saved to: /content/drive/MyDrive/bm25_reranked_top3_merged.csv\n"
          ]
        }
      ],
      "source": [
        "#Step 1: Set the path to your batch folder\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Folder where your reranked CSVs are stored\n",
        "rerank_dir = \"/content/drive/MyDrive/rerank_batches\"\n",
        "\n",
        "# Get all reranked CSVs\n",
        "files = sorted(glob.glob(f\"{rerank_dir}/reranked_*.csv\"))\n",
        "print(f\" Found {len(files)} batch files.\")\n",
        "\n",
        "#Step 2: Merge all into one DataFrame\n",
        "df_all = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
        "print(\" Merged all batches:\", df_all.shape)\n",
        "df_all.head()\n",
        "\n",
        "#Step 3: Save final merged file to Drive\n",
        "merged_output = \"/content/drive/MyDrive/bm25_reranked_top3_merged.csv\"\n",
        "df_all.to_csv(merged_output, index=False)\n",
        "print(\" Final merged file saved to:\", merged_output)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1167,
          "status": "ok",
          "timestamp": 1758035603661,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "zz4HbAw7Fg7c",
        "outputId": "09446b53-448d-4d74-e333-aeca97c64ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Duplicates found: 9\n"
          ]
        }
      ],
      "source": [
        "#Optional: Verify if there are duplicates\n",
        "dupes = df_all.duplicated(subset=[\"query\", \"response\"])\n",
        "print(\" Duplicates found:\", dupes.sum())\n",
        "\n",
        "# To drop duplicates:\n",
        "df_all = df_all.drop_duplicates(subset=[\"query\", \"response\"]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "executionInfo": {
          "elapsed": 689,
          "status": "ok",
          "timestamp": 1758035688315,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "g_T58kDSF0lh",
        "outputId": "d1497272-9d4c-471b-d804-e943e4880759"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: nan",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-471b0185-a6dc-46df-86ca-310e8de1f16d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>rank</th>\n",
              "      <th>response</th>\n",
              "      <th>rerank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-471b0185-a6dc-46df-86ca-310e8de1f16d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-471b0185-a6dc-46df-86ca-310e8de1f16d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-471b0185-a6dc-46df-86ca-310e8de1f16d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [query, rank, response, rerank_score]\n",
              "Index: []"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check if any duplicate rows span across different files:\n",
        "dupes_df = df_all[df_all.duplicated(subset=[\"query\", \"response\"], keep=False)]\n",
        "dupes_df.sort_values(\"query\").head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 268,
          "status": "ok",
          "timestamp": 1758035727621,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "4cGV709fF-La",
        "outputId": "4d8ff294-7adf-4a76-d2f8-62293cc5440b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique queries: 50000\n",
            "Total rows: 149991\n"
          ]
        }
      ],
      "source": [
        "# How many unique queries do you have?\n",
        "print(\"Unique queries:\", df_all['query'].nunique())\n",
        "\n",
        "# How many total rows?\n",
        "print(\"Total rows:\", len(df_all))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 14304,
          "status": "ok",
          "timestamp": 1758036553836,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "SsrdsL0RGr2X",
        "outputId": "f6d86b3a-d7db-462d-fce8-49c5a25a5609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Final cleaned shape: (149991, 4)\n"
          ]
        }
      ],
      "source": [
        "# Drop duplicate (query, response)\n",
        "df_all = df_all.drop_duplicates(subset=[\"query\", \"response\"])\n",
        "\n",
        "# Now, keep only top 3 by rerank_score per query\n",
        "df_all = df_all.sort_values(\"rerank_score\", ascending=False)\n",
        "df_all = df_all.groupby(\"query\").head(3).reset_index(drop=True)\n",
        "\n",
        "print(\" Final cleaned shape:\", df_all.shape)\n",
        "df_all.to_csv(\"/content/drive/MyDrive/bm25_reranked_top3_final_cleaned.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JrU1tNfL-vS"
      },
      "source": [
        "## **Step-by-Step Plan (Baseline RAG Generator Phase)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRNI7LJyjWrH"
      },
      "outputs": [],
      "source": [
        "#1. loading re-ranked results\n",
        "import pandas as pd\n",
        "\n",
        "# Path to your merged and cleaned reranked file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/bm25_reranked_top3_final_cleaned.csv\")\n",
        "\n",
        "# Ensure sorting by rerank score\n",
        "df = df.sort_values([\"query\", \"rerank_score\"], ascending=[True, False])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 905,
          "status": "ok",
          "timestamp": 1758210160234,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "BDseH5xDjj9p",
        "outputId": "241d7efa-dab3-4574-ee5e-f7980317962c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Grouped: 50000 queries\n"
          ]
        }
      ],
      "source": [
        "#2. Group context by query\n",
        "# Group top-3 responses per query\n",
        "grouped = df.groupby(\"query\")[\"response\"].apply(list).reset_index()\n",
        "print(f\" Grouped: {len(grouped)} queries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "2c382734e1ac4296bf996d311b955530",
            "877a875223294d288bd19def15f2cfaa",
            "5234fd26913c48a591d64a91163b5372",
            "15965d1635704db5832b6aaffa688981",
            "9f5eb8dd177d43d181bf4eb21a85eb99",
            "ddae754ea9fe4c6688deef26891bf3a2",
            "6dde8a1722d24e2b81a08762c21a3853"
          ]
        },
        "executionInfo": {
          "elapsed": 38334,
          "status": "ok",
          "timestamp": 1758210209531,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "ZXwsS2J-jvwf",
        "outputId": "77a606ce-82f3-4e77-a376-73407469f24c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c382734e1ac4296bf996d311b955530",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "877a875223294d288bd19def15f2cfaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5234fd26913c48a591d64a91163b5372",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15965d1635704db5832b6aaffa688981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f5eb8dd177d43d181bf4eb21a85eb99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddae754ea9fe4c6688deef26891bf3a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dde8a1722d24e2b81a08762c21a3853",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#3. Preparing Ganerator Model(FLAN-T5)\n",
        "\n",
        "!pip install -q transformers sentencepiece\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9_9BbXvj6eR"
      },
      "outputs": [],
      "source": [
        "#4. Define the generator function\n",
        "import torch\n",
        "\n",
        "def generate_answer_flant5(query, contexts, max_len=256):\n",
        "    context_text = \" \".join(contexts)\n",
        "    prompt = f\"Question: {query}\\nContext: {context_text}\\nAnswer:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_len)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 16942,
          "status": "error",
          "timestamp": 1758210254061,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "rU8Gx-6tkHRM",
        "outputId": "9ca89362-3444-4ddb-96ff-cc25d1893e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_0_1000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_1000_2000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_2000_3000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_3000_4000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_4000_5000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_5000_6000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_6000_7000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_7000_8000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_8000_9000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_9000_10000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_10000_11000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_11000_12000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_12000_13000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_13000_14000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_14000_15000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_15000_16000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_16000_17000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_17000_18000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_18000_19000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_19000_20000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_20000_21000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_21000_22000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_22000_23000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_23000_24000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_24000_25000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_25000_26000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_26000_27000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_27000_28000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_28000_29000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_29000_30000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_30000_31000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_31000_32000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_32000_33000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_33000_34000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_34000_35000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_35000_36000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_36000_37000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_37000_38000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_38000_39000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_39000_40000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_40000_41000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_41000_42000.csv\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-457142251.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer_flant5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"ERROR: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1096081409.py\u001b[0m in \u001b[0;36mgenerate_answer_flant5\u001b[0;34m(query, contexts, max_len)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Question: {query}\\nContext: {context_text}\\nAnswer:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgeneration_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAMPLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGREEDY_SEARCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m             \u001b[0;31m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2540\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2868\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2870\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1764\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1100\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mdo_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             cross_attention_outputs = self.layer[1](\n\u001b[0m\u001b[1;32m    711\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_values, use_cache, query_length, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     ):\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         attention_output = self.EncDecAttention(\n\u001b[1;32m    640\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# half-precision inputs is done in fp32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#5. Chunked processing and saving\n",
        "import os\n",
        "\n",
        "chunk_size = 1000\n",
        "output_dir = \"/content/drive/MyDrive/flant5_answers\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i in range(0, len(grouped), chunk_size):\n",
        "    chunk = grouped.iloc[i:i+chunk_size]\n",
        "    out_path = f\"{output_dir}/answers_{i}_{i+len(chunk)}.csv\"\n",
        "\n",
        "    if os.path.exists(out_path):\n",
        "        print(f\" Skipping already processed: {out_path}\")\n",
        "        continue\n",
        "\n",
        "    results = []\n",
        "    for _, row in chunk.iterrows():\n",
        "        try:\n",
        "            answer = generate_answer_flant5(row[\"query\"], row[\"response\"])\n",
        "        except Exception as e:\n",
        "            answer = f\"ERROR: {e}\"\n",
        "\n",
        "        results.append({\n",
        "            \"query\": row[\"query\"],\n",
        "            \"contexts\": row[\"response\"],\n",
        "            \"generated_answer\": answer\n",
        "        })\n",
        "\n",
        "    pd.DataFrame(results).to_csv(out_path, index=False)\n",
        "    print(f\" Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bz68C-oeyd-",
        "outputId": "cf89ac6c-a7eb-4452-bb4a-49e40ffbfe73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_19000_20000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_20000_21000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_21000_22000.csv\n",
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_22000_23000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 23000-24000: 100%|| 1000/1000 [20:20<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_23000_24000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 24000-25000: 100%|| 1000/1000 [18:57<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_24000_25000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 25000-26000: 100%|| 1000/1000 [21:03<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_25000_26000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 26000-27000: 100%|| 1000/1000 [21:59<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_26000_27000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 27000-28000: 100%|| 1000/1000 [23:10<00:00,  1.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_27000_28000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 28000-29000: 100%|| 1000/1000 [20:21<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_28000_29000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 29000-30000: 100%|| 1000/1000 [21:00<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_29000_30000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 30000-31000: 100%|| 1000/1000 [20:01<00:00,  1.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_30000_31000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 31000-32000: 100%|| 1000/1000 [19:59<00:00,  1.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_31000_32000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 32000-33000:  27%|       | 271/1000 [05:06<10:09,  1.20it/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "chunk_size = 1000\n",
        "start_idx = 19000 # change this to resume later\n",
        "output_dir = \"/content/drive/MyDrive/flant5_answers\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i in range(start_idx, len(grouped), chunk_size):\n",
        "    end = min(i + chunk_size, len(grouped))\n",
        "    out_path = f\"{output_dir}/answers_{i}_{end}.csv\"\n",
        "\n",
        "    if os.path.exists(out_path):\n",
        "        print(f\" Skipping already processed: {out_path}\")\n",
        "        continue\n",
        "\n",
        "    chunk = grouped.iloc[i:end]\n",
        "    results = []\n",
        "\n",
        "    for _, row in tqdm(chunk.iterrows(), total=len(chunk), desc=f\"Generating {i}-{end}\"):\n",
        "        try:\n",
        "            answer = generate_answer_flant5(row[\"query\"], row[\"response\"])\n",
        "        except Exception as e:\n",
        "            answer = f\"ERROR: {e}\"\n",
        "        results.append({\n",
        "            \"query\": row[\"query\"],\n",
        "            \"contexts\": row[\"response\"],\n",
        "            \"generated_answer\": answer\n",
        "        })\n",
        "\n",
        "    pd.DataFrame(results).to_csv(out_path, index=False)\n",
        "    print(f\" Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Or3r-qTeHZ",
        "outputId": "d6b593bf-afec-4152-c1aa-a7b59db23374"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 32000-33000: 100%|| 1000/1000 [19:45<00:00,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_32000_33000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 33000-34000: 100%|| 1000/1000 [20:25<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_33000_34000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 34000-35000: 100%|| 1000/1000 [20:29<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_34000_35000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 35000-36000: 100%|| 1000/1000 [19:19<00:00,  1.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_35000_36000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 36000-37000: 100%|| 1000/1000 [20:49<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_36000_37000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 37000-38000: 100%|| 1000/1000 [23:06<00:00,  1.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_37000_38000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 38000-39000: 100%|| 1000/1000 [22:42<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_38000_39000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 39000-40000: 100%|| 1000/1000 [20:06<00:00,  1.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_39000_40000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 40000-41000: 100%|| 1000/1000 [19:00<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_40000_41000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 41000-42000:  70%|   | 704/1000 [14:24<05:04,  1.03s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "chunk_size = 1000\n",
        "start_idx = 32000 # change this to resume later\n",
        "output_dir = \"/content/drive/MyDrive/flant5_answers\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i in range(start_idx, len(grouped), chunk_size):\n",
        "    end = min(i + chunk_size, len(grouped))\n",
        "    out_path = f\"{output_dir}/answers_{i}_{end}.csv\"\n",
        "\n",
        "    if os.path.exists(out_path):\n",
        "        print(f\" Skipping already processed: {out_path}\")\n",
        "        continue\n",
        "\n",
        "    chunk = grouped.iloc[i:end]\n",
        "    results = []\n",
        "\n",
        "    for _, row in tqdm(chunk.iterrows(), total=len(chunk), desc=f\"Generating {i}-{end}\"):\n",
        "        try:\n",
        "            answer = generate_answer_flant5(row[\"query\"], row[\"response\"])\n",
        "        except Exception as e:\n",
        "            answer = f\"ERROR: {e}\"\n",
        "        results.append({\n",
        "            \"query\": row[\"query\"],\n",
        "            \"contexts\": row[\"response\"],\n",
        "            \"generated_answer\": answer\n",
        "        })\n",
        "\n",
        "    pd.DataFrame(results).to_csv(out_path, index=False)\n",
        "    print(f\" Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6493594,
          "status": "ok",
          "timestamp": 1758216785662,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "nxsr33DSf7sS",
        "outputId": "4fcbf1ab-420c-4d31-ae2e-18aa963bdf4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Skipping already processed: /content/drive/MyDrive/flant5_answers/answers_41000_42000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 42000-43000: 100%|| 1000/1000 [13:32<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_42000_43000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 43000-44000: 100%|| 1000/1000 [14:11<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_43000_44000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 44000-45000: 100%|| 1000/1000 [13:36<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_44000_45000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 45000-46000: 100%|| 1000/1000 [12:47<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_45000_46000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 46000-47000: 100%|| 1000/1000 [13:49<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_46000_47000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 47000-48000: 100%|| 1000/1000 [13:37<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_47000_48000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 48000-49000: 100%|| 1000/1000 [13:01<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_48000_49000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating 49000-50000: 100%|| 1000/1000 [13:36<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/answers_49000_50000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "chunk_size = 1000\n",
        "start_idx = 41000 # change this to resume later\n",
        "output_dir = \"/content/drive/MyDrive/flant5_answers\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i in range(start_idx, len(grouped), chunk_size):\n",
        "    end = min(i + chunk_size, len(grouped))\n",
        "    out_path = f\"{output_dir}/answers_{i}_{end}.csv\"\n",
        "\n",
        "    if os.path.exists(out_path):\n",
        "        print(f\" Skipping already processed: {out_path}\")\n",
        "        continue\n",
        "\n",
        "    chunk = grouped.iloc[i:end]\n",
        "    results = []\n",
        "\n",
        "    for _, row in tqdm(chunk.iterrows(), total=len(chunk), desc=f\"Generating {i}-{end}\"):\n",
        "        try:\n",
        "            answer = generate_answer_flant5(row[\"query\"], row[\"response\"])\n",
        "        except Exception as e:\n",
        "            answer = f\"ERROR: {e}\"\n",
        "        results.append({\n",
        "            \"query\": row[\"query\"],\n",
        "            \"contexts\": row[\"response\"],\n",
        "            \"generated_answer\": answer\n",
        "        })\n",
        "\n",
        "    pd.DataFrame(results).to_csv(out_path, index=False)\n",
        "    print(f\" Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 26233,
          "status": "ok",
          "timestamp": 1758515294409,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "2FBnoqaVbgo0",
        "outputId": "6ea8121a-c70c-49d2-a3d1-816c438c525a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Merged 50 files  /content/drive/MyDrive/flant5_answers/flant5_answers_merged.csv\n",
            " Total rows: 50000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# Set your chunk directory path\n",
        "chunk_dir = \"/content/drive/MyDrive/flant5_answers\"\n",
        "output_file = f\"{chunk_dir}/flant5_answers_merged.csv\"\n",
        "\n",
        "# Get all CSV files in the directory starting with \"answers_\"\n",
        "csv_files = sorted(glob(os.path.join(chunk_dir, \"answers_*.csv\")))\n",
        "\n",
        "# Read and merge\n",
        "merged_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
        "\n",
        "# Optional: Drop duplicate queries (keep first occurrence)\n",
        "# merged_df = merged_df.drop_duplicates(subset=[\"query\"])\n",
        "\n",
        "# Save final merged file\n",
        "merged_df.to_csv(output_file, index=False)\n",
        "print(f\" Merged {len(csv_files)} files  {output_file}\")\n",
        "print(f\" Total rows: {len(merged_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI6G2apTWLG0"
      },
      "source": [
        "## **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7436,
          "status": "ok",
          "timestamp": 1760158324057,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "nHpeGrAQWRG6",
        "outputId": "c59dc891-701e-4f12-e6fa-f557b513da9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q bert-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 16614,
          "status": "ok",
          "timestamp": 1760158340675,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "O91zixjlcN2t",
        "outputId": "d961c43f-8514-4f7d-b8a1-8e81e3dea3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Total cleaned rows: 49987\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/flant5_answers/flant5_answers_merged.csv\"\n",
        "output_dir = \"/content/drive/MyDrive/flant5_answers/bert_chunks\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(input_path)\n",
        "df = df.dropna(subset=[\"generated_answer\", \"contexts\"])  # Clean rows\n",
        "print(f\" Total cleaned rows: {len(df)}\")\n",
        "\n",
        "chunk_size = 5000  # Adjust to your GPU capacity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 21694,
          "status": "ok",
          "timestamp": 1760158362391,
          "user": {
            "displayName": "YoungLearners",
            "userId": "08775624826447299877"
          },
          "user_tz": -360
        },
        "id": "29reShY8d37-",
        "outputId": "0ac82008-0ed8-4a03-8855-c32f040586ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['query', 'contexts', 'generated_answer'],\n",
              "                                                query  \\\n",
              " 0  ! my son 24 years of age suffers from non stop...   \n",
              " 1  % year old son banged his head on door , cried...   \n",
              " 2  ( 34yo female ) mri showed well-circumscribed ...   \n",
              " 3  ( a ) a am using winepress of 2.5 daily ( a ) ...   \n",
              " 4  ( in a girl ) to we had some genital touching ...   \n",
              " \n",
              "                                             contexts  \\\n",
              " 0  [\"hi welcome to chatdoctori have gone through ...   \n",
              " 1  [\"hello. i just read through your question. th...   \n",
              " 2  ['hi, thanks for writing in. it is important t...   \n",
              " 3  ['hello, you are in early stages of insomnia a...   \n",
              " 4  [\"hello, relax down, don't be given up in your...   \n",
              " \n",
              "                                     generated_answer  \n",
              " 0  a balanced diet containing essential nutrients...  \n",
              " 1                                              alarm  \n",
              " 2  enlarged spleen is one of the important organ ...  \n",
              " 3  i have answered your query. let me know if i c...  \n",
              " 4  if something is wrong in someone the simplicit...  )"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the FLAN-T5 answers file\n",
        "file_path = \"/content/drive/MyDrive/flant5_answers/flant5_answers_merged.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows and column names for confirmation\n",
        "df.columns.tolist(), df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "6cdacd159d5f4ad7b0eeafa28be1472a",
            "7c9dc4fbedf244f29e4efd3d051e834c",
            "063b81b888734ef0ad10bf22a2199934",
            "2bcc7d5c8411462eb74343bb7dab1249",
            "c7facaff2554451b9a42267fee761ba0",
            "920660df13f44355abe1361895005920",
            "31d65acf1fc74f1fb6c94a81ac178fee",
            "c56904fee1c9460385b30f57d5fccb66",
            "bec9f49ec1c04eed861ef3e464f7ea9a",
            "fd7e3d8333c54a859660320567ea56ed",
            "ce7d7ba88de545e5911a89a9aa43527f",
            "14f515ee3a2249968a296e0d9869fc12",
            "9a9d21f0830647b3b39b9f60bf949fe2",
            "f5f240c4dfa94623b0664d816db3f55f",
            "33aa7649ce364e0c864b50640129dee4",
            "f519a2317a7d42e6accf2bb85ed5c832",
            "e3650cdcb2a941c9bab69b62d2ecc9c2",
            "ca7997d930ec4a3393ea98b8b71474c3",
            "184a1a80972248e0bb60babe9c5251e0",
            "c3d8548b306c4204836b225feb971f86",
            "6683fadf600844a59f1ac4ca362f78a0",
            "954b22ebbdf441e7aa71e6699d3779bf",
            "a0acb4dc59b74fa2873930c16b691c16",
            "21b0b4b50318460cb74d127e7e3a62bd",
            "d9b973e771fa4f72aab708348eacd8b7",
            "25128912331e49159e158ea6864fd397",
            "e15e4c73bb8a414f966bcb1351353d67",
            "6a0fb1bbe14847a88f20694f85886a3b",
            "ba186b11e3a9448395ce4c94be16fbf8",
            "9c03ac0874d449d1b23c67c5c6db633e",
            "d9ee56c132a4400b99c6f0956afc55ea",
            "de48bc44c75d4a2bbe7c07772a33265c",
            "4da9e793fa944ab5af266b7bd71b6f9a",
            "53dcc3d923284c048f8158584b8952b3",
            "d996f8ba7bc14df7b79c79dd7be469c0",
            "a12dd7bd25834dffb25aa52006d61f9c",
            "fe310783a7fe482e9daa2b5b1bb6fb49",
            "8f18219c4b71490180cf14bccd7c5a6c",
            "606479b9589a4abab8e26ee1fd59bbb4",
            "66b70f0e029542d3a2b9ec679b176911",
            "385ddc8f990d444594cf140ca4f25bde",
            "35fa432156344edebbf8ceb63b13f1cb",
            "a1283eb533ba4006a64c3721f6697829",
            "5a389a55cee24ae6b7ec20f2d096a3c6",
            "5d8a4c7e1e364bcaacbe6ef183586613",
            "491f42bcb0364856b3a878dfeb063346",
            "3762e1953483433abbab91359649930d",
            "03e9dc2dc67f45b4af1483283185ee4b",
            "e9158a62c39e4ad2ac5220cbd2c7a6e7",
            "9c5f55b8c48e4a4ca4bc40c0bf170a85",
            "d97d0b4b08b94049a3a7797334495622",
            "70186a268aff4704a62ea116b941751b",
            "26f4d2dbda064bca8c6f7f816383183f",
            "9b9d9cbd1cb54f6289e439c1a9e08dcf",
            "5bf56a826d2c43dda2c8ad232c977361",
            "28e6fafdd664428b89410f7380cc3974",
            "cac7a57bcfe349e0abb722674505e2a1",
            "edd4dd47d45b48c9aa80a2024c31724d",
            "7ad54b986fac413faeb4302bb519ea57",
            "6e5624f3454e4759b57451feb560f30d",
            "c008a2c0022f4c30af8bcbd0161377de",
            "14daa0c317494034a501c7f18c36e18d",
            "3a7f04f6d06d4c14b27f3cf7995fe386",
            "633ce214bb3b4a3ebbbc8932ba38371d",
            "3e35f98d8a2a4e3eacf5984cc531ef4c",
            "8726623df6eb4f49b5605488f205c9fd"
          ]
        },
        "id": "gpsSuXancQl4",
        "outputId": "c85b49b5-a4ed-4073-8098-dc0830101a59"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cdacd159d5f4ad7b0eeafa28be1472a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14f515ee3a2249968a296e0d9869fc12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0acb4dc59b74fa2873930c16b691c16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53dcc3d923284c048f8158584b8952b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d8a4c7e1e364bcaacbe6ef183586613",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28e6fafdd664428b89410f7380cc3974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " Batching BERTScore...:   0%|          | 1/500 [10:28<87:04:14, 628.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_0_100.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   0%|          | 2/500 [20:08<83:02:14, 600.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_100_200.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   1%|          | 3/500 [29:50<81:42:20, 591.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_200_300.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   1%|          | 4/500 [39:37<81:17:11, 589.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_300_400.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   1%|          | 5/500 [49:12<80:20:16, 584.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_400_500.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   1%|          | 6/500 [58:55<80:07:51, 583.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_500_600.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   1%|         | 7/500 [1:08:33<79:43:03, 582.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_600_700.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   2%|         | 8/500 [1:18:55<81:16:24, 594.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_700_800.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   2%|         | 9/500 [1:28:44<80:53:45, 593.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_800_900.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   2%|         | 10/500 [1:38:32<80:29:33, 591.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_900_1000.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   2%|         | 11/500 [1:48:05<79:34:05, 585.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1000_1100.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   2%|         | 12/500 [1:57:45<79:08:52, 583.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1100_1200.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   3%|         | 13/500 [2:07:22<78:43:28, 581.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1200_1300.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   3%|         | 14/500 [2:17:01<78:26:50, 581.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1300_1400.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   3%|         | 15/500 [2:26:49<78:34:16, 583.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1400_1500.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   3%|         | 16/500 [2:36:37<78:36:39, 584.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1500_1600.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   3%|         | 17/500 [2:46:23<78:28:42, 584.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1600_1700.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r Batching BERTScore...:   4%|         | 18/500 [2:56:19<78:45:15, 588.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved: /content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks/faithfulness_1700_1800.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from bert_score import BERTScorer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Load\n",
        "file_path = \"/content/drive/MyDrive/flant5_answers/flant5_answers_merged.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df = df[[\"query\", \"contexts\", \"generated_answer\"]].dropna()\n",
        "df[\"contexts\"] = df[\"contexts\"].astype(str)\n",
        "df[\"generated_answer\"] = df[\"generated_answer\"].astype(str)\n",
        "\n",
        "# Scorer\n",
        "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "# Output folder\n",
        "save_dir = \"/content/drive/MyDrive/flant5_answers/bert_faithfulness_chunks\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "batch_size = 100\n",
        "\n",
        "# Process in batches\n",
        "for i in tqdm(range(0, len(df), batch_size), desc=\" Batching BERTScore...\"):\n",
        "    batch = df.iloc[i:i+batch_size].copy()\n",
        "    answers = batch[\"generated_answer\"].tolist()\n",
        "    contexts = batch[\"contexts\"].tolist()\n",
        "\n",
        "    try:\n",
        "        _, _, f1 = scorer.score(answers, contexts)\n",
        "        batch[\"faithfulness_score\"] = f1.tolist()\n",
        "    except Exception as e:\n",
        "        print(f\" Error in batch {i}-{i+batch_size}: {e}\")\n",
        "        batch[\"faithfulness_score\"] = [None] * len(batch)\n",
        "\n",
        "    # Save chunk\n",
        "    chunk_path = f\"{save_dir}/faithfulness_{i}_{i+len(batch)}.csv\"\n",
        "    batch.to_csv(chunk_path, index=False)\n",
        "    print(f\" Saved: {chunk_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CBsAZOYXbiZv",
        "7qKSiz1pcWNH",
        "st2WuYWwbXyO",
        "HC5ZvpgjbGr_",
        "oKreE-faanGG",
        "_lMM0B6pcFwW",
        "DAcm7bu7c11b",
        "Itmw4e1Q6DdI",
        "AJGtilxZ6F_I",
        "2gjSmSC4FE4I",
        "17lBIzgtFHNw",
        "OdN_KDCWFfSB",
        "dPLyLrnkBZRo",
        "shozogx1w0z1",
        "siGDFeW2uYle",
        "97XzRQ_4ucMT",
        "fK8E0Bm8ujWG",
        "4tIpvFmiusAI",
        "M43sSxh9u4pM",
        "3JrU1tNfL-vS"
      ],
      "provenance": [
        {
          "file_id": "1qDY5EIMWPzWQPjZHGau9xJ0KMw-h3sAC",
          "timestamp": 1760244507537
        }
      ],
      "mount_file_id": "1qDY5EIMWPzWQPjZHGau9xJ0KMw-h3sAC",
      "authorship_tag": "ABX9TyO+tppKUxVZRXw5936/3blZ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
